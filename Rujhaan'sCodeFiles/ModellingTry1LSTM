{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b0dca40",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-17T17:39:56.611030Z",
     "iopub.status.busy": "2025-04-17T17:39:56.610322Z",
     "iopub.status.idle": "2025-04-17T17:40:13.765364Z",
     "shell.execute_reply": "2025-04-17T17:40:13.764518Z"
    },
    "papermill": {
     "duration": 17.162372,
     "end_time": "2025-04-17T17:40:13.766679",
     "exception": false,
     "start_time": "2025-04-17T17:39:56.604307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 17:40:01.528794: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744911601.756233      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744911601.824012      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ps-dataset/order_data_last_six_month.xlsx - Worksheet.csv\n",
      "/kaggle/input/ps-dataset/associated_order_item_data_last_six_month.xlsx - Worksheet.csv\n",
      "/kaggle/input/customer-behavior-dataset/Customer_Behavior_Data.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score,recall_score,f1_score,precision_score\n",
    "from tensorflow.keras.models import clone_model\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ca63d8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:13.776061Z",
     "iopub.status.busy": "2025-04-17T17:40:13.775605Z",
     "iopub.status.idle": "2025-04-17T17:40:13.780709Z",
     "shell.execute_reply": "2025-04-17T17:40:13.780054Z"
    },
    "papermill": {
     "duration": 0.011144,
     "end_time": "2025-04-17T17:40:13.781969",
     "exception": false,
     "start_time": "2025-04-17T17:40:13.770825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def piechart(series):\n",
    "    \"\"\"\n",
    "    Automatically plots a pie chart from a Pandas Series.\n",
    "    - Uses the series name as the chart title.\n",
    "    - Displays value counts as percentages.\n",
    "    \"\"\"\n",
    "    if not isinstance(series, pd.Series):\n",
    "        raise TypeError(\"Input must be a pandas Series\")\n",
    "\n",
    "    counts = series.value_counts(dropna=False)\n",
    "    labels = counts.index.astype(str)\n",
    "    \n",
    "    # Auto-title using series name or fallback\n",
    "    title = series.name if series.name else \"Pie Chart\"\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90, counterclock=False)\n",
    "    plt.title(title)\n",
    "    plt.axis('equal')  # Equal aspect ratio ensures the pie is circular\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08224e0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:13.790556Z",
     "iopub.status.busy": "2025-04-17T17:40:13.790299Z",
     "iopub.status.idle": "2025-04-17T17:40:13.816250Z",
     "shell.execute_reply": "2025-04-17T17:40:13.815710Z"
    },
    "papermill": {
     "duration": 0.03139,
     "end_time": "2025-04-17T17:40:13.817251",
     "exception": false,
     "start_time": "2025-04-17T17:40:13.785861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "beh_data=pd.read_csv(\"/kaggle/input/customer-behavior-dataset/Customer_Behavior_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce179a09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:13.826374Z",
     "iopub.status.busy": "2025-04-17T17:40:13.825783Z",
     "iopub.status.idle": "2025-04-17T17:40:13.839687Z",
     "shell.execute_reply": "2025-04-17T17:40:13.838931Z"
    },
    "papermill": {
     "duration": 0.019725,
     "end_time": "2025-04-17T17:40:13.840970",
     "exception": false,
     "start_time": "2025-04-17T17:40:13.821245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "zero_people=beh_data[beh_data['Total Orders']<=4]['customer_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f81773d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:13.849594Z",
     "iopub.status.busy": "2025-04-17T17:40:13.849329Z",
     "iopub.status.idle": "2025-04-17T17:40:13.857229Z",
     "shell.execute_reply": "2025-04-17T17:40:13.856725Z"
    },
    "papermill": {
     "duration": 0.013559,
     "end_time": "2025-04-17T17:40:13.858414",
     "exception": false,
     "start_time": "2025-04-17T17:40:13.844855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_1_people=beh_data[((beh_data['Total Orders']<=25) & (beh_data['Total Orders']>4) & (beh_data['Average Order Gap Days']>=14))]['customer_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3d52be5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:13.867338Z",
     "iopub.status.busy": "2025-04-17T17:40:13.866950Z",
     "iopub.status.idle": "2025-04-17T17:40:13.875073Z",
     "shell.execute_reply": "2025-04-17T17:40:13.874516Z"
    },
    "papermill": {
     "duration": 0.013413,
     "end_time": "2025-04-17T17:40:13.876167",
     "exception": false,
     "start_time": "2025-04-17T17:40:13.862754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_2_people = beh_data['customer_id'][~beh_data['customer_id'].isin(cluster_1_people) & ~beh_data['customer_id'].isin(zero_people)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c83790f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:13.884412Z",
     "iopub.status.busy": "2025-04-17T17:40:13.884190Z",
     "iopub.status.idle": "2025-04-17T17:40:14.158146Z",
     "shell.execute_reply": "2025-04-17T17:40:14.157533Z"
    },
    "papermill": {
     "duration": 0.27978,
     "end_time": "2025-04-17T17:40:14.159707",
     "exception": false,
     "start_time": "2025-04-17T17:40:13.879927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"/kaggle/input/ps-dataset/order_data_last_six_month.xlsx - Worksheet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a2221bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:14.169536Z",
     "iopub.status.busy": "2025-04-17T17:40:14.169275Z",
     "iopub.status.idle": "2025-04-17T17:40:14.178379Z",
     "shell.execute_reply": "2025-04-17T17:40:14.177855Z"
    },
    "papermill": {
     "duration": 0.014915,
     "end_time": "2025-04-17T17:40:14.179370",
     "exception": false,
     "start_time": "2025-04-17T17:40:14.164455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data=dataset[dataset['customer_id'].isin(cluster_2_people)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7058264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:14.187444Z",
     "iopub.status.busy": "2025-04-17T17:40:14.187227Z",
     "iopub.status.idle": "2025-04-17T17:40:14.209942Z",
     "shell.execute_reply": "2025-04-17T17:40:14.209239Z"
    },
    "papermill": {
     "duration": 0.028015,
     "end_time": "2025-04-17T17:40:14.211037",
     "exception": false,
     "start_time": "2025-04-17T17:40:14.183022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_date</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>poc_name</th>\n",
       "      <th>poc_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>discount</th>\n",
       "      <th>net_order_amount</th>\n",
       "      <th>profit</th>\n",
       "      <th>order_status</th>\n",
       "      <th>warehouse_name</th>\n",
       "      <th>warehouse_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/04/2025</td>\n",
       "      <td>136349</td>\n",
       "      <td>SO/25-26/000818</td>\n",
       "      <td>5235</td>\n",
       "      <td>Anshu General Store Sector 34</td>\n",
       "      <td>Vikas Gupta</td>\n",
       "      <td>6</td>\n",
       "      <td>19125.00</td>\n",
       "      <td>1650.00</td>\n",
       "      <td>17475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>Noida</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30/01/2025</td>\n",
       "      <td>110393</td>\n",
       "      <td>SO/24-25/90881</td>\n",
       "      <td>7622</td>\n",
       "      <td>bhai di rasoi</td>\n",
       "      <td>Abhay Srimali</td>\n",
       "      <td>7814</td>\n",
       "      <td>9670.48</td>\n",
       "      <td>735.48</td>\n",
       "      <td>8935.0</td>\n",
       "      <td>-56.4</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>Greater NOIDA</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26/12/2024</td>\n",
       "      <td>96182</td>\n",
       "      <td>SO/24-25/77411</td>\n",
       "      <td>2223</td>\n",
       "      <td>Bikaner Sweets ( Harola )</td>\n",
       "      <td>Swatantra</td>\n",
       "      <td>25</td>\n",
       "      <td>4520.00</td>\n",
       "      <td>420.00</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>Noida</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30/12/2024</td>\n",
       "      <td>97858</td>\n",
       "      <td>SO/24-25/78975</td>\n",
       "      <td>6903</td>\n",
       "      <td>Lucknow kirana store</td>\n",
       "      <td>Raj Kumar</td>\n",
       "      <td>7039</td>\n",
       "      <td>1700.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>Gomti Nagar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>04/01/2025</td>\n",
       "      <td>99588</td>\n",
       "      <td>SO/24-25/80618</td>\n",
       "      <td>2296</td>\n",
       "      <td>Champaran Meat House</td>\n",
       "      <td>Ajay Singh</td>\n",
       "      <td>38</td>\n",
       "      <td>5074.00</td>\n",
       "      <td>214.00</td>\n",
       "      <td>4860.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>Telibagh</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_date  order_id     order_number  customer_id  \\\n",
       "0  03/04/2025    136349  SO/25-26/000818         5235   \n",
       "1  30/01/2025    110393   SO/24-25/90881         7622   \n",
       "3  26/12/2024     96182   SO/24-25/77411         2223   \n",
       "4  30/12/2024     97858   SO/24-25/78975         6903   \n",
       "5  04/01/2025     99588   SO/24-25/80618         2296   \n",
       "\n",
       "                    customer_name       poc_name  poc_id    amount  discount  \\\n",
       "0  Anshu General Store Sector 34     Vikas Gupta       6  19125.00   1650.00   \n",
       "1                  bhai di rasoi   Abhay Srimali    7814   9670.48    735.48   \n",
       "3       Bikaner Sweets ( Harola )      Swatantra      25   4520.00    420.00   \n",
       "4            Lucknow kirana store      Raj Kumar    7039   1700.00      0.00   \n",
       "5            Champaran Meat House     Ajay Singh      38   5074.00    214.00   \n",
       "\n",
       "   net_order_amount  profit order_status warehouse_name  warehouse_id  \n",
       "0           17475.0     0.0       CLOSED          Noida             3  \n",
       "1            8935.0   -56.4       CLOSED  Greater NOIDA             6  \n",
       "3            4100.0    40.0       CLOSED          Noida             3  \n",
       "4            1700.0   -88.0       CLOSED    Gomti Nagar             1  \n",
       "5            4860.0    10.0       CLOSED       Telibagh             2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b85c8e5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:14.220060Z",
     "iopub.status.busy": "2025-04-17T17:40:14.219659Z",
     "iopub.status.idle": "2025-04-17T17:40:14.226636Z",
     "shell.execute_reply": "2025-04-17T17:40:14.225706Z"
    },
    "papermill": {
     "duration": 0.012665,
     "end_time": "2025-04-17T17:40:14.227821",
     "exception": false,
     "start_time": "2025-04-17T17:40:14.215156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/404819675.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.drop(['order_number','customer_name','poc_name','poc_id','amount','profit','order_status','warehouse_id'],axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_data.drop(['order_number','customer_name','poc_name','poc_id','amount','profit','order_status','warehouse_id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79fb0a4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:14.236593Z",
     "iopub.status.busy": "2025-04-17T17:40:14.236371Z",
     "iopub.status.idle": "2025-04-17T17:40:14.317299Z",
     "shell.execute_reply": "2025-04-17T17:40:14.316569Z"
    },
    "papermill": {
     "duration": 0.086811,
     "end_time": "2025-04-17T17:40:14.318589",
     "exception": false,
     "start_time": "2025-04-17T17:40:14.231778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>daily_order_count</th>\n",
       "      <th>discount</th>\n",
       "      <th>net_order_amount</th>\n",
       "      <th>warehouse_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4710.0</td>\n",
       "      <td>Telibagh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-06</td>\n",
       "      <td>1</td>\n",
       "      <td>120.00</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>Telibagh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-07</td>\n",
       "      <td>1</td>\n",
       "      <td>150.00</td>\n",
       "      <td>12900.0</td>\n",
       "      <td>Telibagh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-09</td>\n",
       "      <td>1</td>\n",
       "      <td>200.00</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>Telibagh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-10</td>\n",
       "      <td>1</td>\n",
       "      <td>273.76</td>\n",
       "      <td>5580.0</td>\n",
       "      <td>Telibagh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50025</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-03</td>\n",
       "      <td>1</td>\n",
       "      <td>540.00</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>Greater NOIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50026</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-07</td>\n",
       "      <td>1</td>\n",
       "      <td>530.00</td>\n",
       "      <td>6450.0</td>\n",
       "      <td>Greater NOIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50027</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-08</td>\n",
       "      <td>1</td>\n",
       "      <td>481.00</td>\n",
       "      <td>5890.0</td>\n",
       "      <td>Greater NOIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50028</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>721.00</td>\n",
       "      <td>8650.0</td>\n",
       "      <td>Greater NOIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50029</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>1</td>\n",
       "      <td>710.00</td>\n",
       "      <td>8630.0</td>\n",
       "      <td>Greater NOIDA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50030 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id order_date  daily_order_count  discount  net_order_amount  \\\n",
       "0                1 2024-10-01                  1      0.00            4710.0   \n",
       "1                1 2024-10-06                  1    120.00            2220.0   \n",
       "2                1 2024-10-07                  1    150.00           12900.0   \n",
       "3                1 2024-10-09                  1    200.00            3210.0   \n",
       "4                1 2024-10-10                  1    273.76            5580.0   \n",
       "...            ...        ...                ...       ...               ...   \n",
       "50025         9158 2025-04-03                  1    540.00            6300.0   \n",
       "50026         9158 2025-04-07                  1    530.00            6450.0   \n",
       "50027         9158 2025-04-08                  1    481.00            5890.0   \n",
       "50028         9158 2025-04-09                  1    721.00            8650.0   \n",
       "50029         9158 2025-04-10                  1    710.00            8630.0   \n",
       "\n",
       "      warehouse_name  \n",
       "0           Telibagh  \n",
       "1           Telibagh  \n",
       "2           Telibagh  \n",
       "3           Telibagh  \n",
       "4           Telibagh  \n",
       "...              ...  \n",
       "50025  Greater NOIDA  \n",
       "50026  Greater NOIDA  \n",
       "50027  Greater NOIDA  \n",
       "50028  Greater NOIDA  \n",
       "50029  Greater NOIDA  \n",
       "\n",
       "[50030 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# assume train_data is your original DataFrame\n",
    "df = train_data.copy()\n",
    "df['order_date'] = pd.to_datetime(df['order_date'], dayfirst=True)\n",
    "\n",
    "# group & aggregate:\n",
    "daily_df = df.groupby(['customer_id','order_date']).agg(\n",
    "    daily_order_count = ('order_id',       'count'),\n",
    "    discount          = ('discount',       'sum'),\n",
    "    net_order_amount  = ('net_order_amount','sum'),\n",
    "    warehouse_name    = ('warehouse_name', 'first')  # or use mode if you prefer\n",
    ").reset_index()\n",
    "\n",
    "# now daily_df has exactly one row per customer per date\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f47f077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:14.328176Z",
     "iopub.status.busy": "2025-04-17T17:40:14.327944Z",
     "iopub.status.idle": "2025-04-17T17:40:14.344097Z",
     "shell.execute_reply": "2025-04-17T17:40:14.343521Z"
    },
    "papermill": {
     "duration": 0.022206,
     "end_time": "2025-04-17T17:40:14.345297",
     "exception": false,
     "start_time": "2025-04-17T17:40:14.323091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "daily_df_dummy=pd.get_dummies(daily_df,columns=['warehouse_name'],dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25f1a391",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:14.354923Z",
     "iopub.status.busy": "2025-04-17T17:40:14.354674Z",
     "iopub.status.idle": "2025-04-17T17:40:14.368042Z",
     "shell.execute_reply": "2025-04-17T17:40:14.367397Z"
    },
    "papermill": {
     "duration": 0.019448,
     "end_time": "2025-04-17T17:40:14.369148",
     "exception": false,
     "start_time": "2025-04-17T17:40:14.349700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>daily_order_count</th>\n",
       "      <th>discount</th>\n",
       "      <th>net_order_amount</th>\n",
       "      <th>warehouse_name_Ayodhya</th>\n",
       "      <th>warehouse_name_Gomti Nagar</th>\n",
       "      <th>warehouse_name_Greater NOIDA</th>\n",
       "      <th>warehouse_name_Noida</th>\n",
       "      <th>warehouse_name_Telibagh</th>\n",
       "      <th>warehouse_name_Unnao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4710.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-06</td>\n",
       "      <td>1</td>\n",
       "      <td>120.00</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-07</td>\n",
       "      <td>1</td>\n",
       "      <td>150.00</td>\n",
       "      <td>12900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-09</td>\n",
       "      <td>1</td>\n",
       "      <td>200.00</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-10</td>\n",
       "      <td>1</td>\n",
       "      <td>273.76</td>\n",
       "      <td>5580.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50025</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-03</td>\n",
       "      <td>1</td>\n",
       "      <td>540.00</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50026</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-07</td>\n",
       "      <td>1</td>\n",
       "      <td>530.00</td>\n",
       "      <td>6450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50027</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-08</td>\n",
       "      <td>1</td>\n",
       "      <td>481.00</td>\n",
       "      <td>5890.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50028</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>721.00</td>\n",
       "      <td>8650.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50029</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>1</td>\n",
       "      <td>710.00</td>\n",
       "      <td>8630.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50030 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id order_date  daily_order_count  discount  net_order_amount  \\\n",
       "0                1 2024-10-01                  1      0.00            4710.0   \n",
       "1                1 2024-10-06                  1    120.00            2220.0   \n",
       "2                1 2024-10-07                  1    150.00           12900.0   \n",
       "3                1 2024-10-09                  1    200.00            3210.0   \n",
       "4                1 2024-10-10                  1    273.76            5580.0   \n",
       "...            ...        ...                ...       ...               ...   \n",
       "50025         9158 2025-04-03                  1    540.00            6300.0   \n",
       "50026         9158 2025-04-07                  1    530.00            6450.0   \n",
       "50027         9158 2025-04-08                  1    481.00            5890.0   \n",
       "50028         9158 2025-04-09                  1    721.00            8650.0   \n",
       "50029         9158 2025-04-10                  1    710.00            8630.0   \n",
       "\n",
       "       warehouse_name_Ayodhya  warehouse_name_Gomti Nagar  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "...                       ...                         ...   \n",
       "50025                       0                           0   \n",
       "50026                       0                           0   \n",
       "50027                       0                           0   \n",
       "50028                       0                           0   \n",
       "50029                       0                           0   \n",
       "\n",
       "       warehouse_name_Greater NOIDA  warehouse_name_Noida  \\\n",
       "0                                 0                     0   \n",
       "1                                 0                     0   \n",
       "2                                 0                     0   \n",
       "3                                 0                     0   \n",
       "4                                 0                     0   \n",
       "...                             ...                   ...   \n",
       "50025                             1                     0   \n",
       "50026                             1                     0   \n",
       "50027                             1                     0   \n",
       "50028                             1                     0   \n",
       "50029                             1                     0   \n",
       "\n",
       "       warehouse_name_Telibagh  warehouse_name_Unnao  \n",
       "0                            1                     0  \n",
       "1                            1                     0  \n",
       "2                            1                     0  \n",
       "3                            1                     0  \n",
       "4                            1                     0  \n",
       "...                        ...                   ...  \n",
       "50025                        0                     0  \n",
       "50026                        0                     0  \n",
       "50027                        0                     0  \n",
       "50028                        0                     0  \n",
       "50029                        0                     0  \n",
       "\n",
       "[50030 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_df_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b86a6beb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:14.379387Z",
     "iopub.status.busy": "2025-04-17T17:40:14.379155Z",
     "iopub.status.idle": "2025-04-17T17:40:14.382318Z",
     "shell.execute_reply": "2025-04-17T17:40:14.381764Z"
    },
    "papermill": {
     "duration": 0.009474,
     "end_time": "2025-04-17T17:40:14.383424",
     "exception": false,
     "start_time": "2025-04-17T17:40:14.373950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 30\n",
    "PRED_HORIZON = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc72628c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:14.393972Z",
     "iopub.status.busy": "2025-04-17T17:40:14.393691Z",
     "iopub.status.idle": "2025-04-17T17:40:19.571149Z",
     "shell.execute_reply": "2025-04-17T17:40:19.570253Z"
    },
    "papermill": {
     "duration": 5.184471,
     "end_time": "2025-04-17T17:40:19.572574",
     "exception": false,
     "start_time": "2025-04-17T17:40:14.388103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1932/1932 [00:04<00:00, 418.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (180411, 30, 9)\n",
      "y shape: (180411, 14)\n"
     ]
    }
   ],
   "source": [
    "df = daily_df_dummy.copy()\n",
    "df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "\n",
    "# Identify feature columns (everything except customer_id and date)\n",
    "feature_cols = [c for c in df.columns \n",
    "                if c not in ('customer_id','order_date')]\n",
    "\n",
    "# Container for sequences\n",
    "X, y = [], []\n",
    "\n",
    "# Process each customer individually\n",
    "for cust_id, group in tqdm(df.groupby('customer_id'), total=df['customer_id'].nunique()):\n",
    "    # 1) build a full daily index for this customer\n",
    "    group = group.set_index('order_date').sort_index()\n",
    "    full_idx = pd.date_range(group.index.min(), group.index.max(), freq='D')\n",
    "    group = group.reindex(full_idx).fillna(0)\n",
    "    \n",
    "    # keep customer_id and date for indexing\n",
    "    group['customer_id'] = cust_id\n",
    "    group['date']        = group.index\n",
    "    \n",
    "    # 2) extract feature matrix and target vector\n",
    "    data = group[feature_cols].values\n",
    "    targets = (group['daily_order_count'] > 0).astype(int).values  # 0/1 each day\n",
    "    \n",
    "    # 3) sliding windows\n",
    "    n = len(group)\n",
    "    for start in range(n - SEQ_LEN - PRED_HORIZON + 1):\n",
    "        end   = start + SEQ_LEN\n",
    "        fend  = end + PRED_HORIZON\n",
    "        \n",
    "        X.append(data[start:end, :])         # shape (30, num_features)\n",
    "        y.append(targets[end:fend])          # shape (14,)\n",
    "        \n",
    "# 4) convert to numpy arrays\n",
    "X = np.stack(X)   # (num_samples, 30, num_features)\n",
    "y = np.stack(y)   # (num_samples, 14)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c919788a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:19.588980Z",
     "iopub.status.busy": "2025-04-17T17:40:19.588752Z",
     "iopub.status.idle": "2025-04-17T17:40:19.824431Z",
     "shell.execute_reply": "2025-04-17T17:40:19.823513Z"
    },
    "papermill": {
     "duration": 0.245426,
     "end_time": "2025-04-17T17:40:19.826029",
     "exception": false,
     "start_time": "2025-04-17T17:40:19.580603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=0.4,random_state=42)\n",
    "X_cv,X_test,Y_cv,Y_test=train_test_split(X_test,Y_test,test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "168f9461",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:19.840752Z",
     "iopub.status.busy": "2025-04-17T17:40:19.840447Z",
     "iopub.status.idle": "2025-04-17T17:40:19.846378Z",
     "shell.execute_reply": "2025-04-17T17:40:19.845518Z"
    },
    "papermill": {
     "duration": 0.014651,
     "end_time": "2025-04-17T17:40:19.847584",
     "exception": false,
     "start_time": "2025-04-17T17:40:19.832933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6807aa38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:19.861907Z",
     "iopub.status.busy": "2025-04-17T17:40:19.861676Z",
     "iopub.status.idle": "2025-04-17T17:40:22.791837Z",
     "shell.execute_reply": "2025-04-17T17:40:22.791108Z"
    },
    "papermill": {
     "duration": 2.938897,
     "end_time": "2025-04-17T17:40:22.793290",
     "exception": false,
     "start_time": "2025-04-17T17:40:19.854393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744911621.228780      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1744911621.229467      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">70,656</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m70,656\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m49,408\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,606</span> (478.93 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m122,606\u001b[0m (478.93 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,606</span> (478.93 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m122,606\u001b[0m (478.93 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Assuming you have already defined:\n",
    "# SEQ_LEN = 30\n",
    "# PRED_HORIZON = 14\n",
    "# feature_cols = [...]  # list of your input column names\n",
    "\n",
    "NUM_FEATURES = len(feature_cols)\n",
    "\n",
    "model = Sequential([\n",
    "    # 1st LSTM layer, returns sequences so we can stack another LSTM\n",
    "    LSTM(128, input_shape=(SEQ_LEN, NUM_FEATURES), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # 2nd LSTM layer\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # Dense “bottleneck” to learn combined features\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    # Final output: 14 sigmoid neurons, one per future day\n",
    "    Dense(PRED_HORIZON, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4988b517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:22.809238Z",
     "iopub.status.busy": "2025-04-17T17:40:22.808452Z",
     "iopub.status.idle": "2025-04-17T17:40:22.812158Z",
     "shell.execute_reply": "2025-04-17T17:40:22.811635Z"
    },
    "papermill": {
     "duration": 0.01263,
     "end_time": "2025-04-17T17:40:22.813178",
     "exception": false,
     "start_time": "2025-04-17T17:40:22.800548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.weights.h5',      # Path to save the model weights\n",
    "    monitor='val_loss',                    # Metric to monitor\n",
    "    save_best_only=True,                   # Save only the best weights\n",
    "    save_weights_only=True,                # Save only weights (not full model)\n",
    "    mode='min',                            # 'min' for loss, 'max' for accuracy\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e27db25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:40:22.827985Z",
     "iopub.status.busy": "2025-04-17T17:40:22.827773Z",
     "iopub.status.idle": "2025-04-17T18:03:54.917728Z",
     "shell.execute_reply": "2025-04-17T18:03:54.917048Z"
    },
    "papermill": {
     "duration": 1412.099187,
     "end_time": "2025-04-17T18:03:54.919393",
     "exception": false,
     "start_time": "2025-04-17T17:40:22.820206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744911627.561981      61 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0758 - loss: 0.5104\n",
      "Epoch 1: val_loss improved from inf to 0.43504, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.0758 - loss: 0.5103 - val_accuracy: 0.1016 - val_loss: 0.4350\n",
      "Epoch 2/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0702 - loss: 0.4433\n",
      "Epoch 2: val_loss improved from 0.43504 to 0.43397, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0702 - loss: 0.4433 - val_accuracy: 0.0880 - val_loss: 0.4340\n",
      "Epoch 3/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0791 - loss: 0.4400\n",
      "Epoch 3: val_loss improved from 0.43397 to 0.43356, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0791 - loss: 0.4400 - val_accuracy: 0.0764 - val_loss: 0.4336\n",
      "Epoch 4/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0820 - loss: 0.4386\n",
      "Epoch 4: val_loss improved from 0.43356 to 0.43323, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0820 - loss: 0.4386 - val_accuracy: 0.1177 - val_loss: 0.4332\n",
      "Epoch 5/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0901 - loss: 0.4379\n",
      "Epoch 5: val_loss improved from 0.43323 to 0.43311, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0901 - loss: 0.4379 - val_accuracy: 0.1017 - val_loss: 0.4331\n",
      "Epoch 6/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0887 - loss: 0.4377\n",
      "Epoch 6: val_loss improved from 0.43311 to 0.43308, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0887 - loss: 0.4377 - val_accuracy: 0.1218 - val_loss: 0.4331\n",
      "Epoch 7/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0964 - loss: 0.4370\n",
      "Epoch 7: val_loss improved from 0.43308 to 0.43300, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0964 - loss: 0.4370 - val_accuracy: 0.1045 - val_loss: 0.4330\n",
      "Epoch 8/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0879 - loss: 0.4366\n",
      "Epoch 8: val_loss improved from 0.43300 to 0.43295, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0879 - loss: 0.4366 - val_accuracy: 0.1313 - val_loss: 0.4330\n",
      "Epoch 9/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0928 - loss: 0.4364\n",
      "Epoch 9: val_loss improved from 0.43295 to 0.43288, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0928 - loss: 0.4364 - val_accuracy: 0.1327 - val_loss: 0.4329\n",
      "Epoch 10/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1023 - loss: 0.4355\n",
      "Epoch 10: val_loss did not improve from 0.43288\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1023 - loss: 0.4355 - val_accuracy: 0.1441 - val_loss: 0.4331\n",
      "Epoch 11/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0989 - loss: 0.4358\n",
      "Epoch 11: val_loss did not improve from 0.43288\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0989 - loss: 0.4358 - val_accuracy: 0.1258 - val_loss: 0.4330\n",
      "Epoch 12/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1090 - loss: 0.4366\n",
      "Epoch 12: val_loss improved from 0.43288 to 0.43278, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1090 - loss: 0.4366 - val_accuracy: 0.1600 - val_loss: 0.4328\n",
      "Epoch 13/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1064 - loss: 0.4359\n",
      "Epoch 13: val_loss improved from 0.43278 to 0.43278, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1064 - loss: 0.4359 - val_accuracy: 0.1578 - val_loss: 0.4328\n",
      "Epoch 14/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1183 - loss: 0.4358\n",
      "Epoch 14: val_loss improved from 0.43278 to 0.43269, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1183 - loss: 0.4358 - val_accuracy: 0.1450 - val_loss: 0.4327\n",
      "Epoch 15/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1149 - loss: 0.4335\n",
      "Epoch 15: val_loss improved from 0.43269 to 0.43262, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1149 - loss: 0.4335 - val_accuracy: 0.1532 - val_loss: 0.4326\n",
      "Epoch 16/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1201 - loss: 0.4348\n",
      "Epoch 16: val_loss improved from 0.43262 to 0.43256, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1201 - loss: 0.4348 - val_accuracy: 0.1324 - val_loss: 0.4326\n",
      "Epoch 17/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1245 - loss: 0.4343\n",
      "Epoch 17: val_loss improved from 0.43256 to 0.43244, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1245 - loss: 0.4343 - val_accuracy: 0.1301 - val_loss: 0.4324\n",
      "Epoch 18/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1173 - loss: 0.4354\n",
      "Epoch 18: val_loss did not improve from 0.43244\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1173 - loss: 0.4354 - val_accuracy: 0.1509 - val_loss: 0.4324\n",
      "Epoch 19/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1226 - loss: 0.4341\n",
      "Epoch 19: val_loss did not improve from 0.43244\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1226 - loss: 0.4341 - val_accuracy: 0.1509 - val_loss: 0.4326\n",
      "Epoch 20/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1369 - loss: 0.4348\n",
      "Epoch 20: val_loss improved from 0.43244 to 0.43227, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1369 - loss: 0.4348 - val_accuracy: 0.1269 - val_loss: 0.4323\n",
      "Epoch 21/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1293 - loss: 0.4343\n",
      "Epoch 21: val_loss improved from 0.43227 to 0.43225, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1293 - loss: 0.4343 - val_accuracy: 0.1442 - val_loss: 0.4323\n",
      "Epoch 22/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1361 - loss: 0.4347\n",
      "Epoch 22: val_loss improved from 0.43225 to 0.43225, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1361 - loss: 0.4347 - val_accuracy: 0.1301 - val_loss: 0.4322\n",
      "Epoch 23/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1228 - loss: 0.4326\n",
      "Epoch 23: val_loss did not improve from 0.43225\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1228 - loss: 0.4326 - val_accuracy: 0.1453 - val_loss: 0.4326\n",
      "Epoch 24/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1306 - loss: 0.4343\n",
      "Epoch 24: val_loss did not improve from 0.43225\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1306 - loss: 0.4343 - val_accuracy: 0.1422 - val_loss: 0.4326\n",
      "Epoch 25/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1240 - loss: 0.4347\n",
      "Epoch 25: val_loss did not improve from 0.43225\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1240 - loss: 0.4347 - val_accuracy: 0.1492 - val_loss: 0.4325\n",
      "Epoch 26/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1341 - loss: 0.4335\n",
      "Epoch 26: val_loss improved from 0.43225 to 0.43209, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1341 - loss: 0.4335 - val_accuracy: 0.1499 - val_loss: 0.4321\n",
      "Epoch 27/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1365 - loss: 0.4342\n",
      "Epoch 27: val_loss improved from 0.43209 to 0.43188, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1365 - loss: 0.4342 - val_accuracy: 0.1379 - val_loss: 0.4319\n",
      "Epoch 28/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1356 - loss: 0.4342\n",
      "Epoch 28: val_loss did not improve from 0.43188\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1356 - loss: 0.4342 - val_accuracy: 0.1310 - val_loss: 0.4321\n",
      "Epoch 29/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1335 - loss: 0.4341\n",
      "Epoch 29: val_loss improved from 0.43188 to 0.43174, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1335 - loss: 0.4341 - val_accuracy: 0.1418 - val_loss: 0.4317\n",
      "Epoch 30/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1303 - loss: 0.4342\n",
      "Epoch 30: val_loss did not improve from 0.43174\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1304 - loss: 0.4342 - val_accuracy: 0.1648 - val_loss: 0.4318\n",
      "Epoch 31/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1446 - loss: 0.4334\n",
      "Epoch 31: val_loss improved from 0.43174 to 0.43154, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1446 - loss: 0.4334 - val_accuracy: 0.1533 - val_loss: 0.4315\n",
      "Epoch 32/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1391 - loss: 0.4331\n",
      "Epoch 32: val_loss improved from 0.43154 to 0.43140, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1391 - loss: 0.4331 - val_accuracy: 0.1493 - val_loss: 0.4314\n",
      "Epoch 33/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1438 - loss: 0.4335\n",
      "Epoch 33: val_loss did not improve from 0.43140\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1438 - loss: 0.4335 - val_accuracy: 0.1415 - val_loss: 0.4319\n",
      "Epoch 34/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1430 - loss: 0.4331\n",
      "Epoch 34: val_loss did not improve from 0.43140\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1430 - loss: 0.4331 - val_accuracy: 0.1402 - val_loss: 0.4316\n",
      "Epoch 35/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1350 - loss: 0.4321\n",
      "Epoch 35: val_loss did not improve from 0.43140\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1350 - loss: 0.4321 - val_accuracy: 0.1538 - val_loss: 0.4318\n",
      "Epoch 36/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1489 - loss: 0.4338\n",
      "Epoch 36: val_loss improved from 0.43140 to 0.43130, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1489 - loss: 0.4338 - val_accuracy: 0.1432 - val_loss: 0.4313\n",
      "Epoch 37/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1448 - loss: 0.4326\n",
      "Epoch 37: val_loss did not improve from 0.43130\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1448 - loss: 0.4326 - val_accuracy: 0.1469 - val_loss: 0.4317\n",
      "Epoch 38/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1425 - loss: 0.4328\n",
      "Epoch 38: val_loss did not improve from 0.43130\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1425 - loss: 0.4328 - val_accuracy: 0.1536 - val_loss: 0.4316\n",
      "Epoch 39/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1493 - loss: 0.4326\n",
      "Epoch 39: val_loss improved from 0.43130 to 0.43123, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1493 - loss: 0.4326 - val_accuracy: 0.1553 - val_loss: 0.4312\n",
      "Epoch 40/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1489 - loss: 0.4331\n",
      "Epoch 40: val_loss did not improve from 0.43123\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1489 - loss: 0.4331 - val_accuracy: 0.1507 - val_loss: 0.4312\n",
      "Epoch 41/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1468 - loss: 0.4329\n",
      "Epoch 41: val_loss did not improve from 0.43123\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1468 - loss: 0.4329 - val_accuracy: 0.1571 - val_loss: 0.4313\n",
      "Epoch 42/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1552 - loss: 0.4320\n",
      "Epoch 42: val_loss improved from 0.43123 to 0.43111, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1552 - loss: 0.4320 - val_accuracy: 0.1413 - val_loss: 0.4311\n",
      "Epoch 43/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1449 - loss: 0.4324\n",
      "Epoch 43: val_loss improved from 0.43111 to 0.43085, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1449 - loss: 0.4324 - val_accuracy: 0.1450 - val_loss: 0.4308\n",
      "Epoch 44/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1485 - loss: 0.4317\n",
      "Epoch 44: val_loss improved from 0.43085 to 0.43074, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1485 - loss: 0.4317 - val_accuracy: 0.1386 - val_loss: 0.4307\n",
      "Epoch 45/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1444 - loss: 0.4326\n",
      "Epoch 45: val_loss did not improve from 0.43074\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1445 - loss: 0.4326 - val_accuracy: 0.1521 - val_loss: 0.4308\n",
      "Epoch 46/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1450 - loss: 0.4319\n",
      "Epoch 46: val_loss did not improve from 0.43074\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1450 - loss: 0.4319 - val_accuracy: 0.1612 - val_loss: 0.4309\n",
      "Epoch 47/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1461 - loss: 0.4321\n",
      "Epoch 47: val_loss improved from 0.43074 to 0.43052, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1461 - loss: 0.4321 - val_accuracy: 0.1695 - val_loss: 0.4305\n",
      "Epoch 48/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1502 - loss: 0.4324\n",
      "Epoch 48: val_loss improved from 0.43052 to 0.43039, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1502 - loss: 0.4324 - val_accuracy: 0.1463 - val_loss: 0.4304\n",
      "Epoch 49/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1454 - loss: 0.4319\n",
      "Epoch 49: val_loss improved from 0.43039 to 0.43032, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1454 - loss: 0.4319 - val_accuracy: 0.1513 - val_loss: 0.4303\n",
      "Epoch 50/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1528 - loss: 0.4321\n",
      "Epoch 50: val_loss did not improve from 0.43032\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1528 - loss: 0.4321 - val_accuracy: 0.1416 - val_loss: 0.4307\n",
      "Epoch 51/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1496 - loss: 0.4323\n",
      "Epoch 51: val_loss did not improve from 0.43032\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1496 - loss: 0.4323 - val_accuracy: 0.1555 - val_loss: 0.4305\n",
      "Epoch 52/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1514 - loss: 0.4313\n",
      "Epoch 52: val_loss did not improve from 0.43032\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1514 - loss: 0.4313 - val_accuracy: 0.1502 - val_loss: 0.4307\n",
      "Epoch 53/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1528 - loss: 0.4310\n",
      "Epoch 53: val_loss improved from 0.43032 to 0.43021, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1528 - loss: 0.4310 - val_accuracy: 0.1518 - val_loss: 0.4302\n",
      "Epoch 54/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1499 - loss: 0.4309\n",
      "Epoch 54: val_loss did not improve from 0.43021\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1499 - loss: 0.4309 - val_accuracy: 0.1558 - val_loss: 0.4302\n",
      "Epoch 55/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1480 - loss: 0.4312\n",
      "Epoch 55: val_loss improved from 0.43021 to 0.43009, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1480 - loss: 0.4312 - val_accuracy: 0.1496 - val_loss: 0.4301\n",
      "Epoch 56/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1534 - loss: 0.4318\n",
      "Epoch 56: val_loss improved from 0.43009 to 0.42988, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1534 - loss: 0.4318 - val_accuracy: 0.1637 - val_loss: 0.4299\n",
      "Epoch 57/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1551 - loss: 0.4300\n",
      "Epoch 57: val_loss improved from 0.42988 to 0.42970, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1551 - loss: 0.4300 - val_accuracy: 0.1460 - val_loss: 0.4297\n",
      "Epoch 58/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1535 - loss: 0.4302\n",
      "Epoch 58: val_loss did not improve from 0.42970\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1535 - loss: 0.4302 - val_accuracy: 0.1572 - val_loss: 0.4299\n",
      "Epoch 59/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1500 - loss: 0.4315\n",
      "Epoch 59: val_loss improved from 0.42970 to 0.42955, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1500 - loss: 0.4315 - val_accuracy: 0.1596 - val_loss: 0.4296\n",
      "Epoch 60/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1558 - loss: 0.4302\n",
      "Epoch 60: val_loss did not improve from 0.42955\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1558 - loss: 0.4302 - val_accuracy: 0.1595 - val_loss: 0.4298\n",
      "Epoch 61/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1542 - loss: 0.4318\n",
      "Epoch 61: val_loss improved from 0.42955 to 0.42952, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1542 - loss: 0.4318 - val_accuracy: 0.1456 - val_loss: 0.4295\n",
      "Epoch 62/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1546 - loss: 0.4296\n",
      "Epoch 62: val_loss improved from 0.42952 to 0.42942, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1546 - loss: 0.4296 - val_accuracy: 0.1497 - val_loss: 0.4294\n",
      "Epoch 63/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1515 - loss: 0.4299\n",
      "Epoch 63: val_loss improved from 0.42942 to 0.42911, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1515 - loss: 0.4299 - val_accuracy: 0.1372 - val_loss: 0.4291\n",
      "Epoch 64/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1485 - loss: 0.4304\n",
      "Epoch 64: val_loss improved from 0.42911 to 0.42908, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1485 - loss: 0.4304 - val_accuracy: 0.1343 - val_loss: 0.4291\n",
      "Epoch 65/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1460 - loss: 0.4300\n",
      "Epoch 65: val_loss did not improve from 0.42908\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1460 - loss: 0.4300 - val_accuracy: 0.1615 - val_loss: 0.4293\n",
      "Epoch 66/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1517 - loss: 0.4303\n",
      "Epoch 66: val_loss improved from 0.42908 to 0.42892, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1517 - loss: 0.4303 - val_accuracy: 0.1541 - val_loss: 0.4289\n",
      "Epoch 67/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1528 - loss: 0.4306\n",
      "Epoch 67: val_loss did not improve from 0.42892\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1528 - loss: 0.4306 - val_accuracy: 0.1471 - val_loss: 0.4291\n",
      "Epoch 68/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1549 - loss: 0.4292\n",
      "Epoch 68: val_loss improved from 0.42892 to 0.42885, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.1549 - loss: 0.4292 - val_accuracy: 0.1530 - val_loss: 0.4289\n",
      "Epoch 69/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1548 - loss: 0.4300\n",
      "Epoch 69: val_loss improved from 0.42885 to 0.42851, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1548 - loss: 0.4300 - val_accuracy: 0.1416 - val_loss: 0.4285\n",
      "Epoch 70/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1518 - loss: 0.4288\n",
      "Epoch 70: val_loss did not improve from 0.42851\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1518 - loss: 0.4288 - val_accuracy: 0.1515 - val_loss: 0.4287\n",
      "Epoch 71/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1521 - loss: 0.4281\n",
      "Epoch 71: val_loss did not improve from 0.42851\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1521 - loss: 0.4281 - val_accuracy: 0.1538 - val_loss: 0.4288\n",
      "Epoch 72/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1551 - loss: 0.4297\n",
      "Epoch 72: val_loss improved from 0.42851 to 0.42827, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1551 - loss: 0.4297 - val_accuracy: 0.1422 - val_loss: 0.4283\n",
      "Epoch 73/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1470 - loss: 0.4291\n",
      "Epoch 73: val_loss improved from 0.42827 to 0.42799, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1470 - loss: 0.4291 - val_accuracy: 0.1527 - val_loss: 0.4280\n",
      "Epoch 74/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1546 - loss: 0.4287\n",
      "Epoch 74: val_loss did not improve from 0.42799\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1546 - loss: 0.4287 - val_accuracy: 0.1313 - val_loss: 0.4282\n",
      "Epoch 75/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1462 - loss: 0.4280\n",
      "Epoch 75: val_loss improved from 0.42799 to 0.42783, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1462 - loss: 0.4280 - val_accuracy: 0.1531 - val_loss: 0.4278\n",
      "Epoch 76/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1547 - loss: 0.4281\n",
      "Epoch 76: val_loss improved from 0.42783 to 0.42762, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1547 - loss: 0.4281 - val_accuracy: 0.1344 - val_loss: 0.4276\n",
      "Epoch 77/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1507 - loss: 0.4279\n",
      "Epoch 77: val_loss did not improve from 0.42762\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.1507 - loss: 0.4279 - val_accuracy: 0.1488 - val_loss: 0.4277\n",
      "Epoch 78/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1547 - loss: 0.4268\n",
      "Epoch 78: val_loss improved from 0.42762 to 0.42731, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1547 - loss: 0.4268 - val_accuracy: 0.1525 - val_loss: 0.4273\n",
      "Epoch 79/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1565 - loss: 0.4282\n",
      "Epoch 79: val_loss improved from 0.42731 to 0.42715, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.1565 - loss: 0.4282 - val_accuracy: 0.1434 - val_loss: 0.4271\n",
      "Epoch 80/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1538 - loss: 0.4280\n",
      "Epoch 80: val_loss improved from 0.42715 to 0.42675, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1538 - loss: 0.4280 - val_accuracy: 0.1548 - val_loss: 0.4268\n",
      "Epoch 81/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1555 - loss: 0.4267\n",
      "Epoch 81: val_loss did not improve from 0.42675\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1555 - loss: 0.4267 - val_accuracy: 0.1528 - val_loss: 0.4272\n",
      "Epoch 82/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1554 - loss: 0.4279\n",
      "Epoch 82: val_loss improved from 0.42675 to 0.42652, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1554 - loss: 0.4279 - val_accuracy: 0.1409 - val_loss: 0.4265\n",
      "Epoch 83/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1492 - loss: 0.4260\n",
      "Epoch 83: val_loss did not improve from 0.42652\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1492 - loss: 0.4260 - val_accuracy: 0.1555 - val_loss: 0.4266\n",
      "Epoch 84/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1535 - loss: 0.4256\n",
      "Epoch 84: val_loss improved from 0.42652 to 0.42629, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1535 - loss: 0.4256 - val_accuracy: 0.1488 - val_loss: 0.4263\n",
      "Epoch 85/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1534 - loss: 0.4259\n",
      "Epoch 85: val_loss did not improve from 0.42629\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1534 - loss: 0.4259 - val_accuracy: 0.1472 - val_loss: 0.4265\n",
      "Epoch 86/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1528 - loss: 0.4260\n",
      "Epoch 86: val_loss improved from 0.42629 to 0.42622, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.1527 - loss: 0.4260 - val_accuracy: 0.1502 - val_loss: 0.4262\n",
      "Epoch 87/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1524 - loss: 0.4256\n",
      "Epoch 87: val_loss improved from 0.42622 to 0.42618, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1524 - loss: 0.4256 - val_accuracy: 0.1492 - val_loss: 0.4262\n",
      "Epoch 88/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1529 - loss: 0.4269\n",
      "Epoch 88: val_loss improved from 0.42618 to 0.42595, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1529 - loss: 0.4269 - val_accuracy: 0.1436 - val_loss: 0.4259\n",
      "Epoch 89/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1523 - loss: 0.4255\n",
      "Epoch 89: val_loss did not improve from 0.42595\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1523 - loss: 0.4255 - val_accuracy: 0.1516 - val_loss: 0.4260\n",
      "Epoch 90/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1530 - loss: 0.4249\n",
      "Epoch 90: val_loss improved from 0.42595 to 0.42531, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.1530 - loss: 0.4249 - val_accuracy: 0.1421 - val_loss: 0.4253\n",
      "Epoch 91/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1509 - loss: 0.4253\n",
      "Epoch 91: val_loss did not improve from 0.42531\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1509 - loss: 0.4253 - val_accuracy: 0.1509 - val_loss: 0.4253\n",
      "Epoch 92/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1554 - loss: 0.4240\n",
      "Epoch 92: val_loss improved from 0.42531 to 0.42502, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1554 - loss: 0.4240 - val_accuracy: 0.1533 - val_loss: 0.4250\n",
      "Epoch 93/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1509 - loss: 0.4249\n",
      "Epoch 93: val_loss did not improve from 0.42502\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1509 - loss: 0.4249 - val_accuracy: 0.1509 - val_loss: 0.4250\n",
      "Epoch 94/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1557 - loss: 0.4240\n",
      "Epoch 94: val_loss improved from 0.42502 to 0.42496, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1557 - loss: 0.4240 - val_accuracy: 0.1458 - val_loss: 0.4250\n",
      "Epoch 95/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1536 - loss: 0.4247\n",
      "Epoch 95: val_loss improved from 0.42496 to 0.42487, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1536 - loss: 0.4247 - val_accuracy: 0.1479 - val_loss: 0.4249\n",
      "Epoch 96/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1535 - loss: 0.4238\n",
      "Epoch 96: val_loss improved from 0.42487 to 0.42443, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1535 - loss: 0.4238 - val_accuracy: 0.1423 - val_loss: 0.4244\n",
      "Epoch 97/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1473 - loss: 0.4244\n",
      "Epoch 97: val_loss did not improve from 0.42443\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1473 - loss: 0.4244 - val_accuracy: 0.1586 - val_loss: 0.4244\n",
      "Epoch 98/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1539 - loss: 0.4226\n",
      "Epoch 98: val_loss did not improve from 0.42443\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1539 - loss: 0.4226 - val_accuracy: 0.1577 - val_loss: 0.4245\n",
      "Epoch 99/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1526 - loss: 0.4236\n",
      "Epoch 99: val_loss improved from 0.42443 to 0.42424, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.1527 - loss: 0.4236 - val_accuracy: 0.1497 - val_loss: 0.4242\n",
      "Epoch 100/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1553 - loss: 0.4230\n",
      "Epoch 100: val_loss improved from 0.42424 to 0.42422, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1553 - loss: 0.4230 - val_accuracy: 0.1578 - val_loss: 0.4242\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_cv, Y_cv),\n",
    "    callbacks=[checkpoint]  # You can add ModelCheckpoint or EarlyStopping if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c09d53ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T18:03:57.300226Z",
     "iopub.status.busy": "2025-04-17T18:03:57.299939Z",
     "iopub.status.idle": "2025-04-17T18:03:57.558388Z",
     "shell.execute_reply": "2025-04-17T18:03:57.557663Z"
    },
    "papermill": {
     "duration": 1.443123,
     "end_time": "2025-04-17T18:03:57.559547",
     "exception": false,
     "start_time": "2025-04-17T18:03:56.116424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7de64cb2bb10>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b56f2a6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T18:03:59.821141Z",
     "iopub.status.busy": "2025-04-17T18:03:59.820527Z",
     "iopub.status.idle": "2025-04-17T18:04:15.305697Z",
     "shell.execute_reply": "2025-04-17T18:04:15.304813Z"
    },
    "papermill": {
     "duration": 16.636935,
     "end_time": "2025-04-17T18:04:15.307175",
     "exception": false,
     "start_time": "2025-04-17T18:03:58.670240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3383/3383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step\n",
      "Training Data:\n",
      "Accuracy is  0.1442178001958502\n",
      "Precision is  0.6633740878963768\n",
      "Recall is  0.16528948569111349\n",
      "F1 Score is  0.26460512342363346\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Validation Data:\n",
      "Accuracy is  0.14043013136744084\n",
      "Precision is  0.6599319238402982\n",
      "Recall is  0.16547979843955088\n",
      "F1 Score is  0.26455661989912255\n"
     ]
    }
   ],
   "source": [
    "pred_train=model.predict(X_train)\n",
    "pred_train_bin= (pred_train > 0.5).astype(int)\n",
    "print(\"Training Data:\")\n",
    "\n",
    "print(\"Accuracy is \",accuracy_score(Y_train,pred_train_bin))\n",
    "print(\"Precision is \",precision_score(Y_train,pred_train_bin,average='macro'))\n",
    "print(\"Recall is \",recall_score(Y_train,pred_train_bin,average='macro'))\n",
    "print(\"F1 Score is \",f1_score(Y_train,pred_train_bin,average='macro'))\n",
    "\n",
    "pred_val=model.predict(X_cv)\n",
    "pred_val_bin= (pred_val > 0.5).astype(int)\n",
    "print(\"Validation Data:\")\n",
    "\n",
    "print(\"Accuracy is \",accuracy_score(Y_cv,pred_val_bin))\n",
    "print(\"Precision is \",precision_score(Y_cv,pred_val_bin,average='macro'))\n",
    "print(\"Recall is \",recall_score(Y_cv,pred_val_bin,average='macro'))\n",
    "print(\"F1 Score is \",f1_score(Y_cv,pred_val_bin,average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5b2d449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T18:04:17.660620Z",
     "iopub.status.busy": "2025-04-17T18:04:17.660302Z",
     "iopub.status.idle": "2025-04-17T18:04:31.798762Z",
     "shell.execute_reply": "2025-04-17T18:04:31.797828Z"
    },
    "papermill": {
     "duration": 15.311652,
     "end_time": "2025-04-17T18:04:31.800017",
     "exception": false,
     "start_time": "2025-04-17T18:04:16.488365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m3383/3383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
      "Training Data:\n",
      "Accuracy is  0.1442178001958502\n",
      "Precision is  0.6633740878963768\n",
      "Recall is  0.16528948569111349\n",
      "F1 Score is  0.26460512342363346\n",
      "Validation Data:\n",
      "Accuracy is  0.14043013136744084\n",
      "Precision is  0.6599319238402982\n",
      "Recall is  0.16547979843955088\n",
      "F1 Score is  0.26455661989912255\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_best = clone_model(model)\n",
    "\n",
    "# Important: you need to compile it again\n",
    "model_best.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Load the best saved weights\n",
    "model_best.load_weights('best_model.weights.h5')\n",
    "pred_val=model_best.predict(X_cv)\n",
    "pred_val_bin= (pred_val > 0.5).astype(int)\n",
    "pred_train=model_best.predict(X_train)\n",
    "pred_train_bin= (pred_train> 0.5).astype(int)\n",
    "print(\"Training Data:\")\n",
    "\n",
    "print(\"Accuracy is \",accuracy_score(Y_train,pred_train_bin))\n",
    "print(\"Precision is \",precision_score(Y_train,pred_train_bin,average='macro'))\n",
    "print(\"Recall is \",recall_score(Y_train,pred_train_bin,average='macro'))\n",
    "print(\"F1 Score is \",f1_score(Y_train,pred_train_bin,average='macro'))\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "\n",
    "print(\"Accuracy is \",accuracy_score(Y_cv,pred_val_bin))\n",
    "print(\"Precision is \",precision_score(Y_cv,pred_val_bin,average='macro'))\n",
    "print(\"Recall is \",recall_score(Y_cv,pred_val_bin,average='macro'))\n",
    "print(\"F1 Score is \",f1_score(Y_cv,pred_val_bin,average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced10aaf",
   "metadata": {
    "papermill": {
     "duration": 1.178107,
     "end_time": "2025-04-17T18:04:34.132051",
     "exception": false,
     "start_time": "2025-04-17T18:04:32.953944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7141798,
     "sourceId": 11402349,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7154869,
     "sourceId": 11424360,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1486.68569,
   "end_time": "2025-04-17T18:04:38.542012",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-17T17:39:51.856322",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
