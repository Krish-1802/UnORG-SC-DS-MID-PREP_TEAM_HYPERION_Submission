{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d44c7e62",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-17T20:41:37.185979Z",
     "iopub.status.busy": "2025-04-17T20:41:37.185107Z",
     "iopub.status.idle": "2025-04-17T20:41:55.629844Z",
     "shell.execute_reply": "2025-04-17T20:41:55.628839Z"
    },
    "papermill": {
     "duration": 18.452627,
     "end_time": "2025-04-17T20:41:55.631251",
     "exception": false,
     "start_time": "2025-04-17T20:41:37.178624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 20:41:42.631781: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744922502.931392      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744922503.010158      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ps-dataset/order_data_last_six_month.xlsx - Worksheet.csv\n",
      "/kaggle/input/ps-dataset/associated_order_item_data_last_six_month.xlsx - Worksheet.csv\n",
      "/kaggle/input/customer-behavior-dataset/Customer_Behavior_Data.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score,recall_score,f1_score,precision_score\n",
    "from tensorflow.keras.models import clone_model\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f05af90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:41:55.640974Z",
     "iopub.status.busy": "2025-04-17T20:41:55.640490Z",
     "iopub.status.idle": "2025-04-17T20:41:55.644754Z",
     "shell.execute_reply": "2025-04-17T20:41:55.643917Z"
    },
    "papermill": {
     "duration": 0.010239,
     "end_time": "2025-04-17T20:41:55.645999",
     "exception": false,
     "start_time": "2025-04-17T20:41:55.635760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "Keras version: 3.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da1f19b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:41:55.654950Z",
     "iopub.status.busy": "2025-04-17T20:41:55.654696Z",
     "iopub.status.idle": "2025-04-17T20:41:55.659719Z",
     "shell.execute_reply": "2025-04-17T20:41:55.658908Z"
    },
    "papermill": {
     "duration": 0.011282,
     "end_time": "2025-04-17T20:41:55.661396",
     "exception": false,
     "start_time": "2025-04-17T20:41:55.650114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def piechart(series):\n",
    "    \"\"\"\n",
    "    Automatically plots a pie chart from a Pandas Series.\n",
    "    - Uses the series name as the chart title.\n",
    "    - Displays value counts as percentages.\n",
    "    \"\"\"\n",
    "    if not isinstance(series, pd.Series):\n",
    "        raise TypeError(\"Input must be a pandas Series\")\n",
    "\n",
    "    counts = series.value_counts(dropna=False)\n",
    "    labels = counts.index.astype(str)\n",
    "    \n",
    "    # Auto-title using series name or fallback\n",
    "    title = series.name if series.name else \"Pie Chart\"\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90, counterclock=False)\n",
    "    plt.title(title)\n",
    "    plt.axis('equal')  # Equal aspect ratio ensures the pie is circular\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9587c0a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:41:55.675355Z",
     "iopub.status.busy": "2025-04-17T20:41:55.674858Z",
     "iopub.status.idle": "2025-04-17T20:41:55.700732Z",
     "shell.execute_reply": "2025-04-17T20:41:55.699857Z"
    },
    "papermill": {
     "duration": 0.034979,
     "end_time": "2025-04-17T20:41:55.702058",
     "exception": false,
     "start_time": "2025-04-17T20:41:55.667079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "beh_data=pd.read_csv(\"/kaggle/input/customer-behavior-dataset/Customer_Behavior_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d94231e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:41:55.711560Z",
     "iopub.status.busy": "2025-04-17T20:41:55.711106Z",
     "iopub.status.idle": "2025-04-17T20:41:55.724765Z",
     "shell.execute_reply": "2025-04-17T20:41:55.724241Z"
    },
    "papermill": {
     "duration": 0.019496,
     "end_time": "2025-04-17T20:41:55.725856",
     "exception": false,
     "start_time": "2025-04-17T20:41:55.706360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "zero_people=beh_data[beh_data['Total Orders']<=4]['customer_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bcff4ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:41:55.734984Z",
     "iopub.status.busy": "2025-04-17T20:41:55.734760Z",
     "iopub.status.idle": "2025-04-17T20:41:55.740229Z",
     "shell.execute_reply": "2025-04-17T20:41:55.739694Z"
    },
    "papermill": {
     "duration": 0.011304,
     "end_time": "2025-04-17T20:41:55.741303",
     "exception": false,
     "start_time": "2025-04-17T20:41:55.729999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_1_people=beh_data[((beh_data['Total Orders']<=25) & (beh_data['Total Orders']>4) & (beh_data['Average Order Gap Days']>=14))]['customer_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49d42747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:41:55.750302Z",
     "iopub.status.busy": "2025-04-17T20:41:55.750087Z",
     "iopub.status.idle": "2025-04-17T20:41:55.759549Z",
     "shell.execute_reply": "2025-04-17T20:41:55.759018Z"
    },
    "papermill": {
     "duration": 0.015385,
     "end_time": "2025-04-17T20:41:55.760751",
     "exception": false,
     "start_time": "2025-04-17T20:41:55.745366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_2_people = beh_data['customer_id'][~beh_data['customer_id'].isin(cluster_1_people) & ~beh_data['customer_id'].isin(zero_people)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c53c2c46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:41:55.770978Z",
     "iopub.status.busy": "2025-04-17T20:41:55.770713Z",
     "iopub.status.idle": "2025-04-17T20:41:56.027525Z",
     "shell.execute_reply": "2025-04-17T20:41:56.026912Z"
    },
    "papermill": {
     "duration": 0.263565,
     "end_time": "2025-04-17T20:41:56.029058",
     "exception": false,
     "start_time": "2025-04-17T20:41:55.765493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"/kaggle/input/ps-dataset/order_data_last_six_month.xlsx - Worksheet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b67da250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:41:56.038683Z",
     "iopub.status.busy": "2025-04-17T20:41:56.038437Z",
     "iopub.status.idle": "2025-04-17T20:41:56.047401Z",
     "shell.execute_reply": "2025-04-17T20:41:56.046889Z"
    },
    "papermill": {
     "duration": 0.014935,
     "end_time": "2025-04-17T20:41:56.048440",
     "exception": false,
     "start_time": "2025-04-17T20:41:56.033505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data=dataset[dataset['customer_id'].isin(cluster_2_people)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0de0092",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:41:56.056726Z",
     "iopub.status.busy": "2025-04-17T20:41:56.056510Z",
     "iopub.status.idle": "2025-04-17T20:41:56.078113Z",
     "shell.execute_reply": "2025-04-17T20:41:56.077474Z"
    },
    "papermill": {
     "duration": 0.026844,
     "end_time": "2025-04-17T20:41:56.079192",
     "exception": false,
     "start_time": "2025-04-17T20:41:56.052348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_date</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>poc_name</th>\n",
       "      <th>poc_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>discount</th>\n",
       "      <th>net_order_amount</th>\n",
       "      <th>profit</th>\n",
       "      <th>order_status</th>\n",
       "      <th>warehouse_name</th>\n",
       "      <th>warehouse_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/04/2025</td>\n",
       "      <td>136349</td>\n",
       "      <td>SO/25-26/000818</td>\n",
       "      <td>5235</td>\n",
       "      <td>Anshu General Store Sector 34</td>\n",
       "      <td>Vikas Gupta</td>\n",
       "      <td>6</td>\n",
       "      <td>19125.00</td>\n",
       "      <td>1650.00</td>\n",
       "      <td>17475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>Noida</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30/01/2025</td>\n",
       "      <td>110393</td>\n",
       "      <td>SO/24-25/90881</td>\n",
       "      <td>7622</td>\n",
       "      <td>bhai di rasoi</td>\n",
       "      <td>Abhay Srimali</td>\n",
       "      <td>7814</td>\n",
       "      <td>9670.48</td>\n",
       "      <td>735.48</td>\n",
       "      <td>8935.0</td>\n",
       "      <td>-56.4</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>Greater NOIDA</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26/12/2024</td>\n",
       "      <td>96182</td>\n",
       "      <td>SO/24-25/77411</td>\n",
       "      <td>2223</td>\n",
       "      <td>Bikaner Sweets ( Harola )</td>\n",
       "      <td>Swatantra</td>\n",
       "      <td>25</td>\n",
       "      <td>4520.00</td>\n",
       "      <td>420.00</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>Noida</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30/12/2024</td>\n",
       "      <td>97858</td>\n",
       "      <td>SO/24-25/78975</td>\n",
       "      <td>6903</td>\n",
       "      <td>Lucknow kirana store</td>\n",
       "      <td>Raj Kumar</td>\n",
       "      <td>7039</td>\n",
       "      <td>1700.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>Gomti Nagar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>04/01/2025</td>\n",
       "      <td>99588</td>\n",
       "      <td>SO/24-25/80618</td>\n",
       "      <td>2296</td>\n",
       "      <td>Champaran Meat House</td>\n",
       "      <td>Ajay Singh</td>\n",
       "      <td>38</td>\n",
       "      <td>5074.00</td>\n",
       "      <td>214.00</td>\n",
       "      <td>4860.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>Telibagh</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_date  order_id     order_number  customer_id  \\\n",
       "0  03/04/2025    136349  SO/25-26/000818         5235   \n",
       "1  30/01/2025    110393   SO/24-25/90881         7622   \n",
       "3  26/12/2024     96182   SO/24-25/77411         2223   \n",
       "4  30/12/2024     97858   SO/24-25/78975         6903   \n",
       "5  04/01/2025     99588   SO/24-25/80618         2296   \n",
       "\n",
       "                    customer_name       poc_name  poc_id    amount  discount  \\\n",
       "0  Anshu General Store Sector 34     Vikas Gupta       6  19125.00   1650.00   \n",
       "1                  bhai di rasoi   Abhay Srimali    7814   9670.48    735.48   \n",
       "3       Bikaner Sweets ( Harola )      Swatantra      25   4520.00    420.00   \n",
       "4            Lucknow kirana store      Raj Kumar    7039   1700.00      0.00   \n",
       "5            Champaran Meat House     Ajay Singh      38   5074.00    214.00   \n",
       "\n",
       "   net_order_amount  profit order_status warehouse_name  warehouse_id  \n",
       "0           17475.0     0.0       CLOSED          Noida             3  \n",
       "1            8935.0   -56.4       CLOSED  Greater NOIDA             6  \n",
       "3            4100.0    40.0       CLOSED          Noida             3  \n",
       "4            1700.0   -88.0       CLOSED    Gomti Nagar             1  \n",
       "5            4860.0    10.0       CLOSED       Telibagh             2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8830daa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:41:56.088238Z",
     "iopub.status.busy": "2025-04-17T20:41:56.088041Z",
     "iopub.status.idle": "2025-04-17T20:41:56.094706Z",
     "shell.execute_reply": "2025-04-17T20:41:56.093906Z"
    },
    "papermill": {
     "duration": 0.01262,
     "end_time": "2025-04-17T20:41:56.095822",
     "exception": false,
     "start_time": "2025-04-17T20:41:56.083202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/404819675.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.drop(['order_number','customer_name','poc_name','poc_id','amount','profit','order_status','warehouse_id'],axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_data.drop(['order_number','customer_name','poc_name','poc_id','amount','profit','order_status','warehouse_id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e53daa5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:41:56.105657Z",
     "iopub.status.busy": "2025-04-17T20:41:56.105276Z",
     "iopub.status.idle": "2025-04-17T20:41:56.190674Z",
     "shell.execute_reply": "2025-04-17T20:41:56.189911Z"
    },
    "papermill": {
     "duration": 0.091525,
     "end_time": "2025-04-17T20:41:56.191887",
     "exception": false,
     "start_time": "2025-04-17T20:41:56.100362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>daily_order_count</th>\n",
       "      <th>discount</th>\n",
       "      <th>net_order_amount</th>\n",
       "      <th>warehouse_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4710.0</td>\n",
       "      <td>Telibagh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-06</td>\n",
       "      <td>1</td>\n",
       "      <td>120.00</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>Telibagh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-07</td>\n",
       "      <td>1</td>\n",
       "      <td>150.00</td>\n",
       "      <td>12900.0</td>\n",
       "      <td>Telibagh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-09</td>\n",
       "      <td>1</td>\n",
       "      <td>200.00</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>Telibagh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-10</td>\n",
       "      <td>1</td>\n",
       "      <td>273.76</td>\n",
       "      <td>5580.0</td>\n",
       "      <td>Telibagh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50025</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-03</td>\n",
       "      <td>1</td>\n",
       "      <td>540.00</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>Greater NOIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50026</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-07</td>\n",
       "      <td>1</td>\n",
       "      <td>530.00</td>\n",
       "      <td>6450.0</td>\n",
       "      <td>Greater NOIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50027</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-08</td>\n",
       "      <td>1</td>\n",
       "      <td>481.00</td>\n",
       "      <td>5890.0</td>\n",
       "      <td>Greater NOIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50028</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>721.00</td>\n",
       "      <td>8650.0</td>\n",
       "      <td>Greater NOIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50029</th>\n",
       "      <td>9158</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>1</td>\n",
       "      <td>710.00</td>\n",
       "      <td>8630.0</td>\n",
       "      <td>Greater NOIDA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50030 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id order_date  daily_order_count  discount  net_order_amount  \\\n",
       "0                1 2024-10-01                  1      0.00            4710.0   \n",
       "1                1 2024-10-06                  1    120.00            2220.0   \n",
       "2                1 2024-10-07                  1    150.00           12900.0   \n",
       "3                1 2024-10-09                  1    200.00            3210.0   \n",
       "4                1 2024-10-10                  1    273.76            5580.0   \n",
       "...            ...        ...                ...       ...               ...   \n",
       "50025         9158 2025-04-03                  1    540.00            6300.0   \n",
       "50026         9158 2025-04-07                  1    530.00            6450.0   \n",
       "50027         9158 2025-04-08                  1    481.00            5890.0   \n",
       "50028         9158 2025-04-09                  1    721.00            8650.0   \n",
       "50029         9158 2025-04-10                  1    710.00            8630.0   \n",
       "\n",
       "      warehouse_name  \n",
       "0           Telibagh  \n",
       "1           Telibagh  \n",
       "2           Telibagh  \n",
       "3           Telibagh  \n",
       "4           Telibagh  \n",
       "...              ...  \n",
       "50025  Greater NOIDA  \n",
       "50026  Greater NOIDA  \n",
       "50027  Greater NOIDA  \n",
       "50028  Greater NOIDA  \n",
       "50029  Greater NOIDA  \n",
       "\n",
       "[50030 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# assume train_data is your original DataFrame\n",
    "df = train_data.copy()\n",
    "df['order_date'] = pd.to_datetime(df['order_date'], dayfirst=True)\n",
    "\n",
    "# group & aggregate:\n",
    "daily_df = df.groupby(['customer_id','order_date']).agg(\n",
    "    daily_order_count = ('order_id',       'count'),\n",
    "    discount          = ('discount',       'sum'),\n",
    "    net_order_amount  = ('net_order_amount','sum'),\n",
    "    warehouse_name    = ('warehouse_name', 'first')  # or use mode if you prefer\n",
    ").reset_index()\n",
    "\n",
    "# now daily_df has exactly one row per customer per date\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3488698f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:41:56.201835Z",
     "iopub.status.busy": "2025-04-17T20:41:56.201628Z",
     "iopub.status.idle": "2025-04-17T20:41:56.218218Z",
     "shell.execute_reply": "2025-04-17T20:41:56.217384Z"
    },
    "papermill": {
     "duration": 0.023003,
     "end_time": "2025-04-17T20:41:56.219551",
     "exception": false,
     "start_time": "2025-04-17T20:41:56.196548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "daily_df_dummy=pd.get_dummies(daily_df,columns=['warehouse_name'],dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e8c8861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:41:56.229993Z",
     "iopub.status.busy": "2025-04-17T20:41:56.229483Z",
     "iopub.status.idle": "2025-04-17T20:41:56.232902Z",
     "shell.execute_reply": "2025-04-17T20:41:56.232132Z"
    },
    "papermill": {
     "duration": 0.009917,
     "end_time": "2025-04-17T20:41:56.234188",
     "exception": false,
     "start_time": "2025-04-17T20:41:56.224271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 30\n",
    "PRED_HORIZON = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d464194a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:41:56.244951Z",
     "iopub.status.busy": "2025-04-17T20:41:56.244262Z",
     "iopub.status.idle": "2025-04-17T20:42:01.640998Z",
     "shell.execute_reply": "2025-04-17T20:42:01.639904Z"
    },
    "papermill": {
     "duration": 5.403463,
     "end_time": "2025-04-17T20:42:01.642273",
     "exception": false,
     "start_time": "2025-04-17T20:41:56.238810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1932/1932 [00:04<00:00, 407.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (180411, 30, 16)\n",
      "y shape: (180411, 14)\n"
     ]
    }
   ],
   "source": [
    "df = daily_df_dummy.copy()\n",
    "df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "\n",
    "# Add 'day_of_week' column\n",
    "df['day_of_week'] = df['order_date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "\n",
    "# One-hot encode 'day_of_week'\n",
    "df = pd.get_dummies(df, columns=['day_of_week'], prefix='dow',dtype='int')\n",
    "\n",
    "# Identify feature columns (exclude ID/date)\n",
    "feature_cols = [c for c in df.columns \n",
    "                if c not in ('customer_id', 'order_date')]\n",
    "\n",
    "# Containers for sequence data\n",
    "X, y = [], []\n",
    "\n",
    "for cust_id, group in tqdm(df.groupby('customer_id'), total=df['customer_id'].nunique()):\n",
    "    group = group.set_index('order_date').sort_index()\n",
    "    full_idx = pd.date_range(group.index.min(), group.index.max(), freq='D')\n",
    "    group = group.reindex(full_idx).fillna(0)\n",
    "    \n",
    "    # keep customer_id and date\n",
    "    group['customer_id'] = cust_id\n",
    "    group['date'] = group.index\n",
    "    \n",
    "    data = group[feature_cols].values\n",
    "    targets = (group['daily_order_count'] > 0).astype(int).values\n",
    "\n",
    "    n = len(group)\n",
    "    for start in range(n - SEQ_LEN - PRED_HORIZON + 1):\n",
    "        end = start + SEQ_LEN\n",
    "        fend = end + PRED_HORIZON\n",
    "        \n",
    "        X.append(data[start:end, :])     # shape: (30, num_features)\n",
    "        y.append(targets[end:fend])      # shape: (14,)\n",
    "\n",
    "X = np.stack(X)\n",
    "y = np.stack(y)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55b09262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:42:01.657631Z",
     "iopub.status.busy": "2025-04-17T20:42:01.657008Z",
     "iopub.status.idle": "2025-04-17T20:42:01.662201Z",
     "shell.execute_reply": "2025-04-17T20:42:01.661613Z"
    },
    "papermill": {
     "duration": 0.01376,
     "end_time": "2025-04-17T20:42:01.663334",
     "exception": false,
     "start_time": "2025-04-17T20:42:01.649574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def binary_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss(y_true, y_pred):\n",
    "        # Clip the predictions to prevent log(0) error\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "        \n",
    "        # Calculate cross-entropy\n",
    "        ce = tf.keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "        \n",
    "        # Calculate p_t\n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        \n",
    "        # Modulating factor\n",
    "        modulating_factor = tf.pow(1.0 - p_t, gamma)\n",
    "        \n",
    "        # Alpha factor\n",
    "        alpha_weight = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
    "        \n",
    "        # Focal Loss\n",
    "        focal_loss = alpha_weight * modulating_factor * ce\n",
    "        return tf.reduce_mean(focal_loss)\n",
    "    \n",
    "    return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80ef198d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:42:01.676569Z",
     "iopub.status.busy": "2025-04-17T20:42:01.676385Z",
     "iopub.status.idle": "2025-04-17T20:42:02.035134Z",
     "shell.execute_reply": "2025-04-17T20:42:02.034494Z"
    },
    "papermill": {
     "duration": 0.367062,
     "end_time": "2025-04-17T20:42:02.036679",
     "exception": false,
     "start_time": "2025-04-17T20:42:01.669617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=0.4,random_state=42)\n",
    "X_cv,X_test,Y_cv,Y_test=train_test_split(X_test,Y_test,test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88a3e755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:42:02.052328Z",
     "iopub.status.busy": "2025-04-17T20:42:02.051783Z",
     "iopub.status.idle": "2025-04-17T20:42:02.599284Z",
     "shell.execute_reply": "2025-04-17T20:42:02.598611Z"
    },
    "papermill": {
     "duration": 0.556543,
     "end_time": "2025-04-17T20:42:02.600754",
     "exception": false,
     "start_time": "2025-04-17T20:42:02.044211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "weights = compute_class_weight(class_weight='balanced',\n",
    "                                classes=[0,1],\n",
    "                                y=y.flatten())\n",
    "class_weight = {0: weights[0], 1: weights[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d035872e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:42:02.616557Z",
     "iopub.status.busy": "2025-04-17T20:42:02.616312Z",
     "iopub.status.idle": "2025-04-17T20:42:02.622383Z",
     "shell.execute_reply": "2025-04-17T20:42:02.621856Z"
    },
    "papermill": {
     "duration": 0.015065,
     "end_time": "2025-04-17T20:42:02.623461",
     "exception": false,
     "start_time": "2025-04-17T20:42:02.608396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45db0cd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:42:02.637120Z",
     "iopub.status.busy": "2025-04-17T20:42:02.636901Z",
     "iopub.status.idle": "2025-04-17T20:42:05.976014Z",
     "shell.execute_reply": "2025-04-17T20:42:05.975445Z"
    },
    "papermill": {
     "duration": 3.347086,
     "end_time": "2025-04-17T20:42:05.977104",
     "exception": false,
     "start_time": "2025-04-17T20:42:02.630018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744922524.346515      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1744922524.347138      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">74,240</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m74,240\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m49,408\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">126,190</span> (492.93 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m126,190\u001b[0m (492.93 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">126,190</span> (492.93 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m126,190\u001b[0m (492.93 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Assuming you have already defined:\n",
    "# SEQ_LEN = 30\n",
    "# PRED_HORIZON = 14\n",
    "# feature_cols = [...]  # list of your input column names\n",
    "\n",
    "NUM_FEATURES = len(feature_cols)\n",
    "\n",
    "model = Sequential([\n",
    "    # 1st LSTM layer, returns sequences so we can stack another LSTM\n",
    "    LSTM(128, input_shape=(SEQ_LEN, NUM_FEATURES), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # 2nd LSTM layer\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # Dense “bottleneck” to learn combined features\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    # Final output: 14 sigmoid neurons, one per future day\n",
    "    Dense(PRED_HORIZON, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss=binary_focal_loss(gamma=2.0, alpha=0.25),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55618ca0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:42:05.992292Z",
     "iopub.status.busy": "2025-04-17T20:42:05.991732Z",
     "iopub.status.idle": "2025-04-17T20:42:05.995208Z",
     "shell.execute_reply": "2025-04-17T20:42:05.994669Z"
    },
    "papermill": {
     "duration": 0.012086,
     "end_time": "2025-04-17T20:42:05.996275",
     "exception": false,
     "start_time": "2025-04-17T20:42:05.984189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.weights.h5',      # Path to save the model weights\n",
    "    monitor='val_loss',                    # Metric to monitor\n",
    "    save_best_only=True,                   # Save only the best weights\n",
    "    save_weights_only=True,                # Save only weights (not full model)\n",
    "    mode='min',                            # 'min' for loss, 'max' for accuracy\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f4e258f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T20:42:06.011030Z",
     "iopub.status.busy": "2025-04-17T20:42:06.010696Z",
     "iopub.status.idle": "2025-04-17T21:05:31.813725Z",
     "shell.execute_reply": "2025-04-17T21:05:31.813153Z"
    },
    "papermill": {
     "duration": 1405.811924,
     "end_time": "2025-04-17T21:05:31.815100",
     "exception": false,
     "start_time": "2025-04-17T20:42:06.003176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744922530.926048      63 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0648 - loss: 0.0720\n",
      "Epoch 1: val_loss improved from inf to 0.04252, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.0648 - loss: 0.0720 - val_accuracy: 0.0252 - val_loss: 0.0425\n",
      "Epoch 2/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0676 - loss: 0.0499\n",
      "Epoch 2: val_loss improved from 0.04252 to 0.04237, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0676 - loss: 0.0499 - val_accuracy: 0.0534 - val_loss: 0.0424\n",
      "Epoch 3/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0712 - loss: 0.0487\n",
      "Epoch 3: val_loss did not improve from 0.04237\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0712 - loss: 0.0487 - val_accuracy: 0.0282 - val_loss: 0.0424\n",
      "Epoch 4/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0751 - loss: 0.0482\n",
      "Epoch 4: val_loss improved from 0.04237 to 0.04233, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0751 - loss: 0.0482 - val_accuracy: 0.0767 - val_loss: 0.0423\n",
      "Epoch 5/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0747 - loss: 0.0479\n",
      "Epoch 5: val_loss did not improve from 0.04233\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0747 - loss: 0.0479 - val_accuracy: 0.0348 - val_loss: 0.0424\n",
      "Epoch 6/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0793 - loss: 0.0479\n",
      "Epoch 6: val_loss improved from 0.04233 to 0.04232, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0794 - loss: 0.0479 - val_accuracy: 0.0730 - val_loss: 0.0423\n",
      "Epoch 7/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0875 - loss: 0.0478\n",
      "Epoch 7: val_loss improved from 0.04232 to 0.04231, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0875 - loss: 0.0478 - val_accuracy: 0.0647 - val_loss: 0.0423\n",
      "Epoch 8/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0871 - loss: 0.0476\n",
      "Epoch 8: val_loss did not improve from 0.04231\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0871 - loss: 0.0476 - val_accuracy: 0.0932 - val_loss: 0.0423\n",
      "Epoch 9/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0985 - loss: 0.0475\n",
      "Epoch 9: val_loss improved from 0.04231 to 0.04229, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0985 - loss: 0.0475 - val_accuracy: 0.0683 - val_loss: 0.0423\n",
      "Epoch 10/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0876 - loss: 0.0474\n",
      "Epoch 10: val_loss improved from 0.04229 to 0.04229, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0876 - loss: 0.0474 - val_accuracy: 0.0767 - val_loss: 0.0423\n",
      "Epoch 11/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0936 - loss: 0.0470\n",
      "Epoch 11: val_loss did not improve from 0.04229\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0936 - loss: 0.0470 - val_accuracy: 0.0568 - val_loss: 0.0423\n",
      "Epoch 12/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0931 - loss: 0.0473\n",
      "Epoch 12: val_loss improved from 0.04229 to 0.04228, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0931 - loss: 0.0473 - val_accuracy: 0.0977 - val_loss: 0.0423\n",
      "Epoch 13/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0931 - loss: 0.0472\n",
      "Epoch 13: val_loss improved from 0.04228 to 0.04228, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.0931 - loss: 0.0472 - val_accuracy: 0.1527 - val_loss: 0.0423\n",
      "Epoch 14/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1089 - loss: 0.0471\n",
      "Epoch 14: val_loss did not improve from 0.04228\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1089 - loss: 0.0471 - val_accuracy: 0.0815 - val_loss: 0.0423\n",
      "Epoch 15/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1067 - loss: 0.0472\n",
      "Epoch 15: val_loss did not improve from 0.04228\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1067 - loss: 0.0472 - val_accuracy: 0.1185 - val_loss: 0.0423\n",
      "Epoch 16/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1127 - loss: 0.0472\n",
      "Epoch 16: val_loss improved from 0.04228 to 0.04225, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1127 - loss: 0.0472 - val_accuracy: 0.1611 - val_loss: 0.0423\n",
      "Epoch 17/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1157 - loss: 0.0472\n",
      "Epoch 17: val_loss improved from 0.04225 to 0.04224, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1157 - loss: 0.0472 - val_accuracy: 0.1118 - val_loss: 0.0422\n",
      "Epoch 18/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1160 - loss: 0.0472\n",
      "Epoch 18: val_loss did not improve from 0.04224\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1160 - loss: 0.0472 - val_accuracy: 0.1325 - val_loss: 0.0423\n",
      "Epoch 19/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1188 - loss: 0.0472\n",
      "Epoch 19: val_loss did not improve from 0.04224\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1189 - loss: 0.0472 - val_accuracy: 0.1434 - val_loss: 0.0423\n",
      "Epoch 20/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1220 - loss: 0.0473\n",
      "Epoch 20: val_loss improved from 0.04224 to 0.04223, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1220 - loss: 0.0473 - val_accuracy: 0.1703 - val_loss: 0.0422\n",
      "Epoch 21/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1277 - loss: 0.0470\n",
      "Epoch 21: val_loss did not improve from 0.04223\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1277 - loss: 0.0470 - val_accuracy: 0.1357 - val_loss: 0.0422\n",
      "Epoch 22/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1272 - loss: 0.0469\n",
      "Epoch 22: val_loss did not improve from 0.04223\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1272 - loss: 0.0469 - val_accuracy: 0.1583 - val_loss: 0.0422\n",
      "Epoch 23/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1312 - loss: 0.0470\n",
      "Epoch 23: val_loss did not improve from 0.04223\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1312 - loss: 0.0470 - val_accuracy: 0.1658 - val_loss: 0.0423\n",
      "Epoch 24/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1351 - loss: 0.0469\n",
      "Epoch 24: val_loss improved from 0.04223 to 0.04221, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1350 - loss: 0.0469 - val_accuracy: 0.1741 - val_loss: 0.0422\n",
      "Epoch 25/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1376 - loss: 0.0470\n",
      "Epoch 25: val_loss did not improve from 0.04221\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1376 - loss: 0.0470 - val_accuracy: 0.1592 - val_loss: 0.0422\n",
      "Epoch 26/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1367 - loss: 0.0471\n",
      "Epoch 26: val_loss improved from 0.04221 to 0.04221, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1367 - loss: 0.0471 - val_accuracy: 0.1501 - val_loss: 0.0422\n",
      "Epoch 27/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1411 - loss: 0.0470\n",
      "Epoch 27: val_loss did not improve from 0.04221\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1411 - loss: 0.0470 - val_accuracy: 0.1316 - val_loss: 0.0422\n",
      "Epoch 28/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1341 - loss: 0.0472\n",
      "Epoch 28: val_loss did not improve from 0.04221\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1341 - loss: 0.0472 - val_accuracy: 0.1628 - val_loss: 0.0422\n",
      "Epoch 29/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1431 - loss: 0.0473\n",
      "Epoch 29: val_loss did not improve from 0.04221\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1431 - loss: 0.0473 - val_accuracy: 0.1532 - val_loss: 0.0422\n",
      "Epoch 30/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1468 - loss: 0.0472\n",
      "Epoch 30: val_loss improved from 0.04221 to 0.04220, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1468 - loss: 0.0472 - val_accuracy: 0.1742 - val_loss: 0.0422\n",
      "Epoch 31/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1439 - loss: 0.0470\n",
      "Epoch 31: val_loss did not improve from 0.04220\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1439 - loss: 0.0470 - val_accuracy: 0.1505 - val_loss: 0.0422\n",
      "Epoch 32/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1443 - loss: 0.0470\n",
      "Epoch 32: val_loss improved from 0.04220 to 0.04218, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1443 - loss: 0.0470 - val_accuracy: 0.1555 - val_loss: 0.0422\n",
      "Epoch 33/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1419 - loss: 0.0469\n",
      "Epoch 33: val_loss did not improve from 0.04218\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1419 - loss: 0.0469 - val_accuracy: 0.1694 - val_loss: 0.0422\n",
      "Epoch 34/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1486 - loss: 0.0470\n",
      "Epoch 34: val_loss did not improve from 0.04218\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1486 - loss: 0.0470 - val_accuracy: 0.1717 - val_loss: 0.0422\n",
      "Epoch 35/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1484 - loss: 0.0471\n",
      "Epoch 35: val_loss improved from 0.04218 to 0.04218, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1484 - loss: 0.0471 - val_accuracy: 0.1682 - val_loss: 0.0422\n",
      "Epoch 36/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1536 - loss: 0.0471\n",
      "Epoch 36: val_loss did not improve from 0.04218\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1536 - loss: 0.0471 - val_accuracy: 0.1537 - val_loss: 0.0422\n",
      "Epoch 37/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1515 - loss: 0.0468\n",
      "Epoch 37: val_loss improved from 0.04218 to 0.04215, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1515 - loss: 0.0468 - val_accuracy: 0.1542 - val_loss: 0.0422\n",
      "Epoch 38/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1461 - loss: 0.0470\n",
      "Epoch 38: val_loss improved from 0.04215 to 0.04215, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1462 - loss: 0.0470 - val_accuracy: 0.1524 - val_loss: 0.0421\n",
      "Epoch 39/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1566 - loss: 0.0472\n",
      "Epoch 39: val_loss did not improve from 0.04215\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1566 - loss: 0.0472 - val_accuracy: 0.1610 - val_loss: 0.0422\n",
      "Epoch 40/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1529 - loss: 0.0467\n",
      "Epoch 40: val_loss improved from 0.04215 to 0.04214, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1529 - loss: 0.0467 - val_accuracy: 0.1698 - val_loss: 0.0421\n",
      "Epoch 41/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1570 - loss: 0.0470\n",
      "Epoch 41: val_loss did not improve from 0.04214\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1570 - loss: 0.0470 - val_accuracy: 0.1508 - val_loss: 0.0422\n",
      "Epoch 42/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1592 - loss: 0.0470\n",
      "Epoch 42: val_loss did not improve from 0.04214\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1592 - loss: 0.0470 - val_accuracy: 0.1414 - val_loss: 0.0421\n",
      "Epoch 43/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1485 - loss: 0.0471\n",
      "Epoch 43: val_loss did not improve from 0.04214\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1486 - loss: 0.0471 - val_accuracy: 0.1537 - val_loss: 0.0421\n",
      "Epoch 44/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1538 - loss: 0.0471\n",
      "Epoch 44: val_loss did not improve from 0.04214\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1538 - loss: 0.0471 - val_accuracy: 0.1584 - val_loss: 0.0422\n",
      "Epoch 45/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1526 - loss: 0.0471\n",
      "Epoch 45: val_loss improved from 0.04214 to 0.04212, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1526 - loss: 0.0471 - val_accuracy: 0.1540 - val_loss: 0.0421\n",
      "Epoch 46/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1607 - loss: 0.0467\n",
      "Epoch 46: val_loss did not improve from 0.04212\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1607 - loss: 0.0467 - val_accuracy: 0.1571 - val_loss: 0.0421\n",
      "Epoch 47/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1606 - loss: 0.0468\n",
      "Epoch 47: val_loss improved from 0.04212 to 0.04212, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1606 - loss: 0.0468 - val_accuracy: 0.1362 - val_loss: 0.0421\n",
      "Epoch 48/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1548 - loss: 0.0468\n",
      "Epoch 48: val_loss did not improve from 0.04212\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1548 - loss: 0.0468 - val_accuracy: 0.1455 - val_loss: 0.0421\n",
      "Epoch 49/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1592 - loss: 0.0470\n",
      "Epoch 49: val_loss improved from 0.04212 to 0.04211, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1592 - loss: 0.0470 - val_accuracy: 0.1594 - val_loss: 0.0421\n",
      "Epoch 50/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1565 - loss: 0.0468\n",
      "Epoch 50: val_loss did not improve from 0.04211\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1565 - loss: 0.0468 - val_accuracy: 0.1599 - val_loss: 0.0421\n",
      "Epoch 51/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1574 - loss: 0.0467\n",
      "Epoch 51: val_loss improved from 0.04211 to 0.04209, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1574 - loss: 0.0467 - val_accuracy: 0.1522 - val_loss: 0.0421\n",
      "Epoch 52/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1510 - loss: 0.0470\n",
      "Epoch 52: val_loss did not improve from 0.04209\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1510 - loss: 0.0470 - val_accuracy: 0.1619 - val_loss: 0.0421\n",
      "Epoch 53/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1611 - loss: 0.0468\n",
      "Epoch 53: val_loss did not improve from 0.04209\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1611 - loss: 0.0468 - val_accuracy: 0.1722 - val_loss: 0.0421\n",
      "Epoch 54/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1564 - loss: 0.0470\n",
      "Epoch 54: val_loss improved from 0.04209 to 0.04208, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1564 - loss: 0.0470 - val_accuracy: 0.1673 - val_loss: 0.0421\n",
      "Epoch 55/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1705 - loss: 0.0467\n",
      "Epoch 55: val_loss did not improve from 0.04208\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1705 - loss: 0.0467 - val_accuracy: 0.1468 - val_loss: 0.0421\n",
      "Epoch 56/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1578 - loss: 0.0468\n",
      "Epoch 56: val_loss did not improve from 0.04208\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1578 - loss: 0.0468 - val_accuracy: 0.1477 - val_loss: 0.0421\n",
      "Epoch 57/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1541 - loss: 0.0467\n",
      "Epoch 57: val_loss improved from 0.04208 to 0.04208, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1541 - loss: 0.0467 - val_accuracy: 0.1457 - val_loss: 0.0421\n",
      "Epoch 58/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1653 - loss: 0.0470\n",
      "Epoch 58: val_loss did not improve from 0.04208\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1653 - loss: 0.0470 - val_accuracy: 0.1501 - val_loss: 0.0421\n",
      "Epoch 59/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1578 - loss: 0.0469\n",
      "Epoch 59: val_loss did not improve from 0.04208\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1578 - loss: 0.0469 - val_accuracy: 0.1455 - val_loss: 0.0421\n",
      "Epoch 60/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1607 - loss: 0.0469\n",
      "Epoch 60: val_loss did not improve from 0.04208\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1607 - loss: 0.0469 - val_accuracy: 0.1522 - val_loss: 0.0421\n",
      "Epoch 61/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1605 - loss: 0.0469\n",
      "Epoch 61: val_loss improved from 0.04208 to 0.04206, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1605 - loss: 0.0469 - val_accuracy: 0.1672 - val_loss: 0.0421\n",
      "Epoch 62/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1642 - loss: 0.0467\n",
      "Epoch 62: val_loss improved from 0.04206 to 0.04205, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1642 - loss: 0.0467 - val_accuracy: 0.1481 - val_loss: 0.0420\n",
      "Epoch 63/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1561 - loss: 0.0467\n",
      "Epoch 63: val_loss improved from 0.04205 to 0.04204, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1561 - loss: 0.0467 - val_accuracy: 0.1540 - val_loss: 0.0420\n",
      "Epoch 64/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1556 - loss: 0.0467\n",
      "Epoch 64: val_loss improved from 0.04204 to 0.04203, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1556 - loss: 0.0467 - val_accuracy: 0.1458 - val_loss: 0.0420\n",
      "Epoch 65/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1536 - loss: 0.0468\n",
      "Epoch 65: val_loss did not improve from 0.04203\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1537 - loss: 0.0468 - val_accuracy: 0.1466 - val_loss: 0.0420\n",
      "Epoch 66/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1520 - loss: 0.0467\n",
      "Epoch 66: val_loss improved from 0.04203 to 0.04201, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1520 - loss: 0.0467 - val_accuracy: 0.1627 - val_loss: 0.0420\n",
      "Epoch 67/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1638 - loss: 0.0467\n",
      "Epoch 67: val_loss improved from 0.04201 to 0.04200, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1638 - loss: 0.0467 - val_accuracy: 0.1392 - val_loss: 0.0420\n",
      "Epoch 68/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1505 - loss: 0.0464\n",
      "Epoch 68: val_loss did not improve from 0.04200\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1505 - loss: 0.0464 - val_accuracy: 0.1557 - val_loss: 0.0420\n",
      "Epoch 69/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1639 - loss: 0.0467\n",
      "Epoch 69: val_loss did not improve from 0.04200\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1639 - loss: 0.0467 - val_accuracy: 0.1522 - val_loss: 0.0420\n",
      "Epoch 70/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1550 - loss: 0.0469\n",
      "Epoch 70: val_loss improved from 0.04200 to 0.04199, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1550 - loss: 0.0469 - val_accuracy: 0.1530 - val_loss: 0.0420\n",
      "Epoch 71/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1584 - loss: 0.0468\n",
      "Epoch 71: val_loss did not improve from 0.04199\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1584 - loss: 0.0468 - val_accuracy: 0.1382 - val_loss: 0.0420\n",
      "Epoch 72/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1517 - loss: 0.0465\n",
      "Epoch 72: val_loss improved from 0.04199 to 0.04199, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1517 - loss: 0.0465 - val_accuracy: 0.1587 - val_loss: 0.0420\n",
      "Epoch 73/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1529 - loss: 0.0467\n",
      "Epoch 73: val_loss did not improve from 0.04199\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1529 - loss: 0.0467 - val_accuracy: 0.1528 - val_loss: 0.0420\n",
      "Epoch 74/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1586 - loss: 0.0467\n",
      "Epoch 74: val_loss improved from 0.04199 to 0.04194, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1586 - loss: 0.0467 - val_accuracy: 0.1551 - val_loss: 0.0419\n",
      "Epoch 75/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1556 - loss: 0.0466\n",
      "Epoch 75: val_loss did not improve from 0.04194\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1556 - loss: 0.0466 - val_accuracy: 0.1553 - val_loss: 0.0419\n",
      "Epoch 76/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1627 - loss: 0.0468\n",
      "Epoch 76: val_loss did not improve from 0.04194\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1627 - loss: 0.0468 - val_accuracy: 0.1356 - val_loss: 0.0420\n",
      "Epoch 77/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1543 - loss: 0.0466\n",
      "Epoch 77: val_loss improved from 0.04194 to 0.04192, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1543 - loss: 0.0466 - val_accuracy: 0.1502 - val_loss: 0.0419\n",
      "Epoch 78/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1598 - loss: 0.0464\n",
      "Epoch 78: val_loss improved from 0.04192 to 0.04191, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1598 - loss: 0.0464 - val_accuracy: 0.1495 - val_loss: 0.0419\n",
      "Epoch 79/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1643 - loss: 0.0467\n",
      "Epoch 79: val_loss did not improve from 0.04191\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.1643 - loss: 0.0467 - val_accuracy: 0.1567 - val_loss: 0.0419\n",
      "Epoch 80/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1621 - loss: 0.0466\n",
      "Epoch 80: val_loss improved from 0.04191 to 0.04189, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1621 - loss: 0.0466 - val_accuracy: 0.1412 - val_loss: 0.0419\n",
      "Epoch 81/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1498 - loss: 0.0466\n",
      "Epoch 81: val_loss did not improve from 0.04189\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1498 - loss: 0.0466 - val_accuracy: 0.1596 - val_loss: 0.0419\n",
      "Epoch 82/100\n",
      "\u001b[1m1690/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1529 - loss: 0.0464\n",
      "Epoch 82: val_loss improved from 0.04189 to 0.04186, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1529 - loss: 0.0464 - val_accuracy: 0.1611 - val_loss: 0.0419\n",
      "Epoch 83/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1594 - loss: 0.0466\n",
      "Epoch 83: val_loss did not improve from 0.04186\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1594 - loss: 0.0466 - val_accuracy: 0.1635 - val_loss: 0.0419\n",
      "Epoch 84/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1620 - loss: 0.0464\n",
      "Epoch 84: val_loss did not improve from 0.04186\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1620 - loss: 0.0464 - val_accuracy: 0.1466 - val_loss: 0.0419\n",
      "Epoch 85/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1542 - loss: 0.0466\n",
      "Epoch 85: val_loss improved from 0.04186 to 0.04185, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1542 - loss: 0.0466 - val_accuracy: 0.1495 - val_loss: 0.0419\n",
      "Epoch 86/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1564 - loss: 0.0464\n",
      "Epoch 86: val_loss did not improve from 0.04185\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.1564 - loss: 0.0464 - val_accuracy: 0.1498 - val_loss: 0.0419\n",
      "Epoch 87/100\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1539 - loss: 0.0466\n",
      "Epoch 87: val_loss did not improve from 0.04185\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1539 - loss: 0.0466 - val_accuracy: 0.1489 - val_loss: 0.0419\n",
      "Epoch 88/100\n",
      "\u001b[1m1691/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1569 - loss: 0.0464\n",
      "Epoch 88: val_loss improved from 0.04185 to 0.04184, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1569 - loss: 0.0464 - val_accuracy: 0.1510 - val_loss: 0.0418\n",
      "Epoch 89/100\n",
      "\u001b[1m1685/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1579 - loss: 0.0463\n",
      "Epoch 89: val_loss improved from 0.04184 to 0.04183, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1579 - loss: 0.0463 - val_accuracy: 0.1422 - val_loss: 0.0418\n",
      "Epoch 90/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1450 - loss: 0.0465\n",
      "Epoch 90: val_loss improved from 0.04183 to 0.04182, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1450 - loss: 0.0465 - val_accuracy: 0.1466 - val_loss: 0.0418\n",
      "Epoch 91/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1562 - loss: 0.0464\n",
      "Epoch 91: val_loss improved from 0.04182 to 0.04178, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1562 - loss: 0.0464 - val_accuracy: 0.1474 - val_loss: 0.0418\n",
      "Epoch 92/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1570 - loss: 0.0463\n",
      "Epoch 92: val_loss did not improve from 0.04178\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1570 - loss: 0.0463 - val_accuracy: 0.1478 - val_loss: 0.0418\n",
      "Epoch 93/100\n",
      "\u001b[1m1686/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1550 - loss: 0.0465\n",
      "Epoch 93: val_loss did not improve from 0.04178\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1550 - loss: 0.0465 - val_accuracy: 0.1480 - val_loss: 0.0418\n",
      "Epoch 94/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1517 - loss: 0.0465\n",
      "Epoch 94: val_loss did not improve from 0.04178\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1517 - loss: 0.0465 - val_accuracy: 0.1461 - val_loss: 0.0418\n",
      "Epoch 95/100\n",
      "\u001b[1m1687/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1527 - loss: 0.0464\n",
      "Epoch 95: val_loss improved from 0.04178 to 0.04173, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1527 - loss: 0.0464 - val_accuracy: 0.1534 - val_loss: 0.0417\n",
      "Epoch 96/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1543 - loss: 0.0464\n",
      "Epoch 96: val_loss did not improve from 0.04173\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1542 - loss: 0.0464 - val_accuracy: 0.1502 - val_loss: 0.0418\n",
      "Epoch 97/100\n",
      "\u001b[1m1689/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1553 - loss: 0.0463\n",
      "Epoch 97: val_loss did not improve from 0.04173\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1553 - loss: 0.0463 - val_accuracy: 0.1434 - val_loss: 0.0417\n",
      "Epoch 98/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1518 - loss: 0.0462\n",
      "Epoch 98: val_loss improved from 0.04173 to 0.04169, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1518 - loss: 0.0462 - val_accuracy: 0.1465 - val_loss: 0.0417\n",
      "Epoch 99/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1575 - loss: 0.0462\n",
      "Epoch 99: val_loss improved from 0.04169 to 0.04167, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1575 - loss: 0.0462 - val_accuracy: 0.1458 - val_loss: 0.0417\n",
      "Epoch 100/100\n",
      "\u001b[1m1688/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1511 - loss: 0.0464\n",
      "Epoch 100: val_loss improved from 0.04167 to 0.04166, saving model to best_model.weights.h5\n",
      "\u001b[1m1692/1692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.1511 - loss: 0.0464 - val_accuracy: 0.1470 - val_loss: 0.0417\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    class_weight=class_weight,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_cv, Y_cv),\n",
    "    callbacks=[checkpoint]  # You can add ModelCheckpoint or EarlyStopping if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91558997",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:05:33.981328Z",
     "iopub.status.busy": "2025-04-17T21:05:33.980538Z",
     "iopub.status.idle": "2025-04-17T21:05:34.274718Z",
     "shell.execute_reply": "2025-04-17T21:05:34.273880Z"
    },
    "papermill": {
     "duration": 1.377727,
     "end_time": "2025-04-17T21:05:34.276290",
     "exception": false,
     "start_time": "2025-04-17T21:05:32.898563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7b7f35751450>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2de3f95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:05:36.393443Z",
     "iopub.status.busy": "2025-04-17T21:05:36.393157Z",
     "iopub.status.idle": "2025-04-17T21:05:51.380224Z",
     "shell.execute_reply": "2025-04-17T21:05:51.379395Z"
    },
    "papermill": {
     "duration": 15.994452,
     "end_time": "2025-04-17T21:05:51.381597",
     "exception": false,
     "start_time": "2025-04-17T21:05:35.387145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3383/3383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
      "Training Data:\n",
      "Accuracy is  0.14405151229606636\n",
      "Precision is  0.8663086377767367\n",
      "Recall is  0.0384336408401992\n",
      "F1 Score is  0.07358883273970976\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Validation Data:\n",
      "Accuracy is  0.1404578460174048\n",
      "Precision is  0.8468921455107431\n",
      "Recall is  0.04219168397660331\n",
      "F1 Score is  0.08036251306943924\n"
     ]
    }
   ],
   "source": [
    "pred_train=model.predict(X_train)\n",
    "pred_train_bin= (pred_train > 0.5).astype(int)\n",
    "print(\"Training Data:\")\n",
    "\n",
    "print(\"Accuracy is \",accuracy_score(Y_train,pred_train_bin))\n",
    "print(\"Precision is \",precision_score(Y_train,pred_train_bin,average='macro'))\n",
    "print(\"Recall is \",recall_score(Y_train,pred_train_bin,average='macro'))\n",
    "print(\"F1 Score is \",f1_score(Y_train,pred_train_bin,average='macro'))\n",
    "\n",
    "pred_val=model.predict(X_cv)\n",
    "pred_val_bin= (pred_val > 0.5).astype(int)\n",
    "print(\"Validation Data:\")\n",
    "\n",
    "print(\"Accuracy is \",accuracy_score(Y_cv,pred_val_bin))\n",
    "print(\"Precision is \",precision_score(Y_cv,pred_val_bin,average='macro'))\n",
    "print(\"Recall is \",recall_score(Y_cv,pred_val_bin,average='macro'))\n",
    "print(\"F1 Score is \",f1_score(Y_cv,pred_val_bin,average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71857d04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:05:53.539773Z",
     "iopub.status.busy": "2025-04-17T21:05:53.539493Z",
     "iopub.status.idle": "2025-04-17T21:06:07.509284Z",
     "shell.execute_reply": "2025-04-17T21:06:07.508309Z"
    },
    "papermill": {
     "duration": 15.043471,
     "end_time": "2025-04-17T21:06:07.510681",
     "exception": false,
     "start_time": "2025-04-17T21:05:52.467210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m3383/3383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
      "Training Data:\n",
      "Accuracy is  0.14405151229606636\n",
      "Precision is  0.8663086377767367\n",
      "Recall is  0.0384336408401992\n",
      "F1 Score is  0.07358883273970976\n",
      "Validation Data:\n",
      "Accuracy is  0.1404578460174048\n",
      "Precision is  0.8468921455107431\n",
      "Recall is  0.04219168397660331\n",
      "F1 Score is  0.08036251306943924\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_best = clone_model(model)\n",
    "\n",
    "# Important: you need to compile it again\n",
    "model_best.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Load the best saved weights\n",
    "model_best.load_weights('best_model.weights.h5')\n",
    "pred_val=model_best.predict(X_cv)\n",
    "pred_val_bin= (pred_val > 0.5).astype(int)\n",
    "pred_train=model_best.predict(X_train)\n",
    "pred_train_bin= (pred_train> 0.5).astype(int)\n",
    "print(\"Training Data:\")\n",
    "\n",
    "print(\"Accuracy is \",accuracy_score(Y_train,pred_train_bin))\n",
    "print(\"Precision is \",precision_score(Y_train,pred_train_bin,average='macro'))\n",
    "print(\"Recall is \",recall_score(Y_train,pred_train_bin,average='macro'))\n",
    "print(\"F1 Score is \",f1_score(Y_train,pred_train_bin,average='macro'))\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "\n",
    "print(\"Accuracy is \",accuracy_score(Y_cv,pred_val_bin))\n",
    "print(\"Precision is \",precision_score(Y_cv,pred_val_bin,average='macro'))\n",
    "print(\"Recall is \",recall_score(Y_cv,pred_val_bin,average='macro'))\n",
    "print(\"F1 Score is \",f1_score(Y_cv,pred_val_bin,average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e821f4b8",
   "metadata": {
    "papermill": {
     "duration": 1.085204,
     "end_time": "2025-04-17T21:06:09.731417",
     "exception": false,
     "start_time": "2025-04-17T21:06:08.646213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7141798,
     "sourceId": 11402349,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7154869,
     "sourceId": 11424360,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1481.60048,
   "end_time": "2025-04-17T21:06:13.803931",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-17T20:41:32.203451",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
